{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG System in images data\n"
      ],
      "metadata": {
        "id": "fMsQDXfmjoBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using google gemini embedding model for retriever"
      ],
      "metadata": {
        "id": "kDy_t7f7F0eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection With Embedding"
      ],
      "metadata": {
        "id": "R9L-S5XDF_d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU facenet-pytorch"
      ],
      "metadata": {
        "id": "CmrsPT-Aki-_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pillow"
      ],
      "metadata": {
        "id": "gGuvTWbwN2w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# libraries of image processing and create embaddings"
      ],
      "metadata": {
        "id": "DlcedlWcgm7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "QKu1Hj5dGkoQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fs0chav3NJ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function to preprocess the image\n",
        "# function to create the embeddings"
      ],
      "metadata": {
        "id": "scbCD4T_gL4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing function to transform the image into tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "# function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "      input_tensor = preprocess_image(image_path)\n",
        "      with torch.no_grad():\n",
        "        embedding = model(input_tensor) # embedding important line\n",
        "      return embedding.squeeze().tolist()\n",
        "    except Exception as e:\n",
        "      print(\"Error\",e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "9CLYedcrOkrW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To create image directory"
      ],
      "metadata": {
        "id": "HVa89l5OgAot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "tA9sSl-jS-_I"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating the embeddings of one image"
      ],
      "metadata": {
        "id": "UhaUEiekgEIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/images/Ahmad-1.jpg\"\n",
        "A1 = create_image_embedding(image_path)"
      ],
      "metadata": {
        "id": "mA226sBUTGwe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# to see the embeddings and dimension"
      ],
      "metadata": {
        "id": "1iERMOGnf1JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(A1))\n",
        "print(\"image embedding\",A1)"
      ],
      "metadata": {
        "id": "IcAcwV_8Vt13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the embeddings of the images"
      ],
      "metadata": {
        "id": "6d6p_eIvfu9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "A1=create_image_embedding(\"/content/images/Ahmad-1.jpg\")\n",
        "A2=create_image_embedding(\"/content/images/Ahmad-2.jpg\")\n",
        "A3=create_image_embedding(\"/content/images/Ahmad-3.jpg\")\n",
        "M1=create_image_embedding(\"/content/images/Muneer-1.png\")\n",
        "M2=create_image_embedding(\"/content/images/Muneer-2.png\")\n",
        "M3=create_image_embedding(\"/content/images/Muneer-3.png\")"
      ],
      "metadata": {
        "id": "vTpoTRSbTEFI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# installing Milvus database"
      ],
      "metadata": {
        "id": "tRQ4TuIzfqHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU milvus-lite\n",
        "!pip install pymilvus"
      ],
      "metadata": {
        "id": "frjlhSBvXFBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating Milvus database"
      ],
      "metadata": {
        "id": "STS1JIEyflRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")"
      ],
      "metadata": {
        "id": "A5A7F2tkXbCS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating the Milvus vector database"
      ],
      "metadata": {
        "id": "CEbYcuxOfcYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension = 512 # the vector we will use in this demo has 384 dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "JkiwuZTaYBlQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making a database of our data means metadata"
      ],
      "metadata": {
        "id": "YaqP_FywfQNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Ahmad\",\"vector\": A1 },\n",
        "    {\"id\": 2, \"person_name\": \"Ahmad\",\"vector\": A2 },\n",
        "    {\"id\": 3, \"person_name\": \"Ahmad\",\"vector\": A3 },\n",
        "    {\"id\": 4, \"person_name\": \"Muneer\",\"vector\": M1 },\n",
        "    {\"id\": 5, \"person_name\": \"Muneer\",\"vector\": M2 },\n",
        "    {\"id\": 6, \"person_name\": \"Muneer\",\"vector\": M3 }\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Eao9-8DAZVSE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inserting embeddings int the Milvus vector store"
      ],
      "metadata": {
        "id": "7hAAXydzfFSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZmO_2Z8KfFNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data,\n",
        "    partition_name=\"images\"\n",
        ")"
      ],
      "metadata": {
        "id": "dA4Db_EUZmJL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing image from embeddings"
      ],
      "metadata": {
        "id": "fWIwZfURe6JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ress = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data = [A1],\n",
        "    limit = 1,\n",
        "    output_fields=[\"person_name\"],\n",
        ")\n",
        "print(ress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBzSTh4jazb2",
        "outputId": "878f5c79-4191-4486-8b0c-5f20b8344665"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 1.0, 'entity': {'person_name': 'Ahmad'}}]\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating embeddings of the new image"
      ],
      "metadata": {
        "id": "L3a-3ZJue03t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A4=create_image_embedding(\"/content/images/Ahmad.jpg\")"
      ],
      "metadata": {
        "id": "McSFtrsSa-m5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YOK7fRSJdTOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with the new image"
      ],
      "metadata": {
        "id": "UWQzhaxkesih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resul = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data = [A4],\n",
        "    limit = 3,\n",
        "    output_fields=[\"id\",\"person_name\"],\n",
        ")\n",
        "print(resul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffmxHWHydVAP",
        "outputId": "2afe467e-f34e-4f65-cf49-48392f9a263c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 5, 'distance': 0.5289016962051392, 'entity': {'person_name': 'Muneer', 'id': 5}}, {'id': 6, 'distance': 0.3440612256526947, 'entity': {'person_name': 'Muneer', 'id': 6}}, {'id': 4, 'distance': 0.15956392884254456, 'entity': {'person_name': 'Muneer', 'id': 4}}]\"]\n"
          ]
        }
      ]
    }
  ]
}