{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**RAG Implementation**"
      ],
      "metadata": {
        "id": "BMkydtzsH1Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain pinecone-client google-generativeai openai tqdm chromadb langchain_community langchain-google-genai --quiet"
      ],
      "metadata": {
        "id": "ZPBpwzIQH8Ny",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Required Modules\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "9GBBG80zIjU2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: loading the dataset\n",
        "path = '/content/faq_bot_university.csv'\n",
        "# changed line\n",
        "loader = CSVLoader(file_path=path, source_column='Answer')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "topTUkOSJwVy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "key=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "dRq6alOLLEDH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "Tj4h_kWSctOW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize Embeddings\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=key,  model=\"models/text-embedding-004\")"
      ],
      "metadata": {
        "id": "0DE0OONIKkCn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create a Chroma Vector Store\n",
        "vector_store = Chroma.from_documents(documents, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "HAnYRHkJMQ25"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(google_api_key=key,\n",
        "                                   model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "_ZlpmOPgMdF8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "print(type(retriever))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP62JmERPmSU",
        "outputId": "4337d7d2-0a6b-4d97-b1e5-04234eeab356"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.vectorstores.base.VectorStoreRetriever'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = retriever.get_relevant_documents(\"admission requirements\")\n",
        "for doc in sample_docs:\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "id": "2RlJl_mAPwMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "chat_template = ChatPromptTemplate.from_messages([\n",
        "    # System Message Prompt Template\n",
        "    SystemMessage(content=\"\"\"You are a Helpful Faq Bot.\n",
        "                  Given a context and question from user,\n",
        "                  you should answer based on the given context.\"\"\"),\n",
        "    # Human Message Prompt Template\n",
        "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "    Answer: \"\"\")\n",
        "])\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | chat_template\n",
        "    | llm\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "4u4ZkYAJdzrl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"\"\"What courses are offered in Computer Science?\"\"\")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_KKGY2-ZeToe",
        "outputId": "448df2de-6197-4b07-d802-4a099d7a8d40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Courses include AI, Data Science, and Web Development.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Set Up Retrieval-Augmented Generation (RAG) Chain\n",
        "from langchain.chains import RetrievalQA\n",
        "faq_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever,chain_type=\"stuff\",)"
      ],
      "metadata": {
        "id": "rBVPv2lOMxMp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Ask a Question\n",
        "question = \"What courses are offered in Computer Science?\"\n",
        "response = faq_chain.run(question)\n",
        "\n",
        "print(\"Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp1v7m49O_Gj",
        "outputId": "c78fec6a-aa12-472a-c327-0df3c933530d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Courses include AI, Data Science, and Web Development.\n"
          ]
        }
      ]
    }
  ]
}