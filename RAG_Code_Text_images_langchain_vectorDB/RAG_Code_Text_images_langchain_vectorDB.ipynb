{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08059da1c93b42989bbe6ae1258fb0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6a1ef40cb4c434da12395d7273d7867",
              "IPY_MODEL_037e2ad20a2d446fb51705c4dac21122",
              "IPY_MODEL_9a527c353ab94827aa6e3dbfa5446e3b"
            ],
            "layout": "IPY_MODEL_4b497909a61f4a429801f76f9073e8b3"
          }
        },
        "d6a1ef40cb4c434da12395d7273d7867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8678bcb539c64d8683aac141a097b48b",
            "placeholder": "​",
            "style": "IPY_MODEL_001a34ad7eed4e4283b925341d498c48",
            "value": "100%"
          }
        },
        "037e2ad20a2d446fb51705c4dac21122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82f32ab79a24b7d89e571813cb3cc85",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb8493af01234449824c54ec2fa5cc36",
            "value": 111898327
          }
        },
        "9a527c353ab94827aa6e3dbfa5446e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811ceb2908f04b4bb52f0256fa56a3ec",
            "placeholder": "​",
            "style": "IPY_MODEL_61fffcb866204593b9d0ad496aec571b",
            "value": " 107M/107M [00:00&lt;00:00, 170MB/s]"
          }
        },
        "4b497909a61f4a429801f76f9073e8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8678bcb539c64d8683aac141a097b48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001a34ad7eed4e4283b925341d498c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c82f32ab79a24b7d89e571813cb3cc85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8493af01234449824c54ec2fa5cc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "811ceb2908f04b4bb52f0256fa56a3ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fffcb866204593b9d0ad496aec571b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "INA8Wgr_DIZy"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "JKa2DgY_DqeC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "G0P5CfVHEGgc",
        "outputId": "9c99dea2-c907-4ead-cb34-405207c81800"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "result : Dict = genai.embed_content(model=\"models/text-embedding-004\",\n",
        "      content=[\"what is the meaning of life\",\n",
        "              \"How does ai work\",\n",
        "              \"How deos brain work\"],\n",
        "      task_type = \"retrieval_document\",\n",
        "      title=\"Embedding of single string\")\n",
        "result['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "Qv7R0X-DE1ki",
        "outputId": "c1b97a1e-7085-427a-eb45-1f73a07449f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-0.028602581,\n",
              "  0.048764728,\n",
              "  -0.03339466,\n",
              "  -0.003734921,\n",
              "  -0.047279656,\n",
              "  0.0037857282,\n",
              "  0.02035182,\n",
              "  0.059677232,\n",
              "  -0.0066421772,\n",
              "  0.007892048,\n",
              "  0.031146767,\n",
              "  -0.029526154,\n",
              "  0.10183836,\n",
              "  -0.037156798,\n",
              "  0.016959282,\n",
              "  -0.113186285,\n",
              "  6.8025925e-05,\n",
              "  0.014039144,\n",
              "  -0.08117846,\n",
              "  -0.012535272,\n",
              "  0.015199548,\n",
              "  0.001107007,\n",
              "  0.05108417,\n",
              "  -0.021950707,\n",
              "  -0.008048343,\n",
              "  0.022889713,\n",
              "  -0.0074632373,\n",
              "  -0.036924668,\n",
              "  -0.010125158,\n",
              "  -0.016015273,\n",
              "  0.07337346,\n",
              "  0.04621874,\n",
              "  0.015818771,\n",
              "  -0.022859208,\n",
              "  0.054621834,\n",
              "  0.03159731,\n",
              "  -0.0047181826,\n",
              "  0.05216193,\n",
              "  0.025140695,\n",
              "  -0.024929,\n",
              "  -0.07248087,\n",
              "  0.018610341,\n",
              "  -0.035985384,\n",
              "  0.056080267,\n",
              "  -0.027600333,\n",
              "  -0.026110215,\n",
              "  -0.011954346,\n",
              "  -0.0040993784,\n",
              "  -0.022410283,\n",
              "  0.061586015,\n",
              "  0.020621223,\n",
              "  0.0138438055,\n",
              "  -0.035095412,\n",
              "  0.022734337,\n",
              "  -0.018321794,\n",
              "  -0.02391703,\n",
              "  -0.0065194927,\n",
              "  -0.03306471,\n",
              "  0.051760323,\n",
              "  -0.051654816,\n",
              "  -0.019638138,\n",
              "  -0.030836077,\n",
              "  -0.026405925,\n",
              "  -0.020456092,\n",
              "  -0.05529541,\n",
              "  0.039503016,\n",
              "  -0.015251184,\n",
              "  0.028444594,\n",
              "  -0.08269349,\n",
              "  0.06318387,\n",
              "  -0.0064488747,\n",
              "  0.042661928,\n",
              "  -0.03153464,\n",
              "  0.041703917,\n",
              "  -0.003865245,\n",
              "  0.03258673,\n",
              "  0.025259672,\n",
              "  0.01303032,\n",
              "  -0.043828685,\n",
              "  0.033467423,\n",
              "  -0.034074616,\n",
              "  0.014432006,\n",
              "  0.06673381,\n",
              "  0.056957796,\n",
              "  0.012603422,\n",
              "  0.0026426676,\n",
              "  -0.028313046,\n",
              "  -0.032339077,\n",
              "  -0.07835036,\n",
              "  -0.011067703,\n",
              "  0.044731013,\n",
              "  0.028827725,\n",
              "  0.0027344476,\n",
              "  0.03398622,\n",
              "  0.05902498,\n",
              "  -0.032857355,\n",
              "  -0.054185666,\n",
              "  -0.07477425,\n",
              "  0.008684187,\n",
              "  0.06841192,\n",
              "  0.06493123,\n",
              "  0.007697028,\n",
              "  -0.0002428911,\n",
              "  -0.04538584,\n",
              "  0.044612262,\n",
              "  0.09126608,\n",
              "  -0.030611742,\n",
              "  -0.029392451,\n",
              "  -0.031200588,\n",
              "  -0.01049448,\n",
              "  0.0071580433,\n",
              "  -0.068255365,\n",
              "  0.023056762,\n",
              "  -0.05583921,\n",
              "  0.028049294,\n",
              "  -0.07785822,\n",
              "  -0.0024063855,\n",
              "  0.01216075,\n",
              "  -0.011107649,\n",
              "  0.00049878564,\n",
              "  0.027286705,\n",
              "  0.066286,\n",
              "  0.0005241089,\n",
              "  0.033714786,\n",
              "  0.07197789,\n",
              "  -0.007910473,\n",
              "  0.010811099,\n",
              "  -0.055490084,\n",
              "  -0.04351834,\n",
              "  -0.024854532,\n",
              "  0.09409316,\n",
              "  -0.11064263,\n",
              "  -0.010965529,\n",
              "  0.01266632,\n",
              "  -0.03699999,\n",
              "  0.006599659,\n",
              "  0.100141905,\n",
              "  -0.009115808,\n",
              "  0.011583495,\n",
              "  -0.017114833,\n",
              "  0.019843385,\n",
              "  -0.019356206,\n",
              "  -0.046111804,\n",
              "  0.025904672,\n",
              "  0.019400885,\n",
              "  -0.035101056,\n",
              "  0.04833208,\n",
              "  0.011553987,\n",
              "  -0.06192332,\n",
              "  -0.008848027,\n",
              "  -0.023370063,\n",
              "  -0.024343768,\n",
              "  0.055171262,\n",
              "  0.008440777,\n",
              "  -0.0059898007,\n",
              "  0.004000568,\n",
              "  0.063289486,\n",
              "  -0.023352368,\n",
              "  0.09209018,\n",
              "  -0.026841035,\n",
              "  -0.0043295617,\n",
              "  -0.082097664,\n",
              "  -0.035071906,\n",
              "  0.004232647,\n",
              "  -0.047252808,\n",
              "  -0.029098049,\n",
              "  0.022881597,\n",
              "  -0.047111347,\n",
              "  0.0011924633,\n",
              "  0.023782194,\n",
              "  -0.0052537057,\n",
              "  0.011565177,\n",
              "  -0.06326157,\n",
              "  -0.035562973,\n",
              "  -0.02794842,\n",
              "  0.013958011,\n",
              "  -0.0163122,\n",
              "  -0.013742172,\n",
              "  -0.009032881,\n",
              "  0.036979277,\n",
              "  0.092798315,\n",
              "  0.036237482,\n",
              "  -0.003779558,\n",
              "  -0.072078854,\n",
              "  0.0039557256,\n",
              "  -0.02729093,\n",
              "  0.005370168,\n",
              "  0.048541136,\n",
              "  0.035057396,\n",
              "  0.06807433,\n",
              "  -0.059403796,\n",
              "  0.027573837,\n",
              "  -0.002031834,\n",
              "  0.033609025,\n",
              "  0.009933962,\n",
              "  -0.051786657,\n",
              "  0.06304865,\n",
              "  -0.005687305,\n",
              "  -0.051449817,\n",
              "  -0.019226182,\n",
              "  0.0010564057,\n",
              "  -0.032568805,\n",
              "  -0.024222149,\n",
              "  -0.04271194,\n",
              "  0.014982165,\n",
              "  -0.009926615,\n",
              "  -0.04100295,\n",
              "  -0.03935563,\n",
              "  0.056761406,\n",
              "  0.0047597755,\n",
              "  -0.024421278,\n",
              "  -0.0065051136,\n",
              "  -0.012049425,\n",
              "  -0.020101257,\n",
              "  0.04852933,\n",
              "  0.036554378,\n",
              "  0.06504549,\n",
              "  -0.007935747,\n",
              "  0.107453376,\n",
              "  0.027783407,\n",
              "  -0.01741637,\n",
              "  -0.02251714,\n",
              "  -0.019013984,\n",
              "  -0.023437139,\n",
              "  0.004718766,\n",
              "  0.011756733,\n",
              "  -0.021665312,\n",
              "  -0.039316904,\n",
              "  -0.018179394,\n",
              "  -0.03551718,\n",
              "  0.012710141,\n",
              "  -0.001678415,\n",
              "  0.0092712585,\n",
              "  -0.0073477547,\n",
              "  -0.0048823617,\n",
              "  0.02119576,\n",
              "  -0.012094981,\n",
              "  0.03482254,\n",
              "  -0.030792182,\n",
              "  -0.020481836,\n",
              "  0.016165977,\n",
              "  5.991714e-05,\n",
              "  -0.0206293,\n",
              "  0.016300648,\n",
              "  0.080307,\n",
              "  0.06756507,\n",
              "  0.035871662,\n",
              "  0.07268734,\n",
              "  -0.012095771,\n",
              "  -0.08771139,\n",
              "  -0.026698824,\n",
              "  -0.010709245,\n",
              "  -0.052628692,\n",
              "  -0.085888386,\n",
              "  -0.024263049,\n",
              "  -0.028915387,\n",
              "  0.035416007,\n",
              "  0.0063633067,\n",
              "  0.0069963625,\n",
              "  -0.00972005,\n",
              "  0.02965353,\n",
              "  -0.08476008,\n",
              "  -0.013433701,\n",
              "  -0.027414417,\n",
              "  -0.039620433,\n",
              "  -0.06094165,\n",
              "  -0.032725267,\n",
              "  -0.036755558,\n",
              "  0.042582307,\n",
              "  -0.062154695,\n",
              "  0.05309395,\n",
              "  -0.018309947,\n",
              "  -0.0017447028,\n",
              "  -0.012824286,\n",
              "  0.03829173,\n",
              "  0.034328025,\n",
              "  0.014626547,\n",
              "  0.023112468,\n",
              "  0.032183394,\n",
              "  -0.0040963083,\n",
              "  0.0042664614,\n",
              "  -0.03514831,\n",
              "  -0.0037453019,\n",
              "  -0.0013908803,\n",
              "  0.014819739,\n",
              "  -0.05682659,\n",
              "  0.0012004153,\n",
              "  0.006076172,\n",
              "  -0.010933894,\n",
              "  0.01636958,\n",
              "  0.051225588,\n",
              "  0.050107375,\n",
              "  0.01466178,\n",
              "  -0.051909216,\n",
              "  0.019156184,\n",
              "  0.018227452,\n",
              "  0.044461876,\n",
              "  0.024563607,\n",
              "  0.020734053,\n",
              "  0.011373266,\n",
              "  0.06015351,\n",
              "  0.056469023,\n",
              "  -0.010929763,\n",
              "  0.030433124,\n",
              "  0.021476502,\n",
              "  0.015344841,\n",
              "  0.055896744,\n",
              "  -0.033459704,\n",
              "  0.020453986,\n",
              "  0.004463393,\n",
              "  -0.0005097184,\n",
              "  0.010695796,\n",
              "  -0.028747955,\n",
              "  0.030097473,\n",
              "  -0.08106168,\n",
              "  -0.026278902,\n",
              "  -0.15617236,\n",
              "  -0.028557478,\n",
              "  -0.020968948,\n",
              "  -0.022611957,\n",
              "  -0.015674803,\n",
              "  0.02324986,\n",
              "  0.026839197,\n",
              "  -0.016760008,\n",
              "  0.07150284,\n",
              "  -0.032698024,\n",
              "  -0.02228707,\n",
              "  0.020998355,\n",
              "  0.009678902,\n",
              "  -0.010691692,\n",
              "  0.0033362182,\n",
              "  0.005696928,\n",
              "  -0.0059842053,\n",
              "  -0.043647267,\n",
              "  0.03868753,\n",
              "  0.0067005935,\n",
              "  -0.016943539,\n",
              "  0.039317407,\n",
              "  0.033061247,\n",
              "  0.050496127,\n",
              "  -0.010919054,\n",
              "  0.0042555286,\n",
              "  0.008621922,\n",
              "  0.021465909,\n",
              "  0.011212551,\n",
              "  -0.027047658,\n",
              "  -0.006573712,\n",
              "  -0.0037393416,\n",
              "  0.017857678,\n",
              "  -0.02530103,\n",
              "  0.0008167413,\n",
              "  0.049087327,\n",
              "  0.011734392,\n",
              "  0.0014967944,\n",
              "  -0.00047204894,\n",
              "  -0.02864514,\n",
              "  0.07361867,\n",
              "  0.03224502,\n",
              "  0.037098117,\n",
              "  0.010780481,\n",
              "  -0.016531792,\n",
              "  -0.02167816,\n",
              "  -0.0045541576,\n",
              "  -0.016877241,\n",
              "  -0.022697546,\n",
              "  -0.04842718,\n",
              "  0.021547452,\n",
              "  0.03723998,\n",
              "  0.015828967,\n",
              "  -0.011696645,\n",
              "  0.04845643,\n",
              "  -0.026231196,\n",
              "  0.0012566899,\n",
              "  0.005638621,\n",
              "  -0.0017035436,\n",
              "  -0.016336469,\n",
              "  -0.007179226,\n",
              "  0.034459274,\n",
              "  0.03561157,\n",
              "  -0.06512083,\n",
              "  -0.045052454,\n",
              "  -0.031347267,\n",
              "  -0.029257702,\n",
              "  -0.004306828,\n",
              "  -0.056167014,\n",
              "  0.068727374,\n",
              "  -0.021578753,\n",
              "  -0.0068942863,\n",
              "  0.02572,\n",
              "  0.01976847,\n",
              "  -0.041440792,\n",
              "  0.045092966,\n",
              "  0.05651891,\n",
              "  0.023320604,\n",
              "  0.010076798,\n",
              "  0.0064933053,\n",
              "  -0.04534056,\n",
              "  0.0389885,\n",
              "  -0.009612391,\n",
              "  0.0472425,\n",
              "  -0.025013324,\n",
              "  -0.037331853,\n",
              "  0.08529712,\n",
              "  0.0036743234,\n",
              "  -0.018142942,\n",
              "  0.005964098,\n",
              "  0.07927093,\n",
              "  0.002134234,\n",
              "  -0.0045203804,\n",
              "  -0.03005965,\n",
              "  -0.039886717,\n",
              "  0.005348769,\n",
              "  -0.0052350163,\n",
              "  0.007604443,\n",
              "  -0.055241544,\n",
              "  -0.014510872,\n",
              "  -0.019026877,\n",
              "  0.0015614638,\n",
              "  -0.0025795826,\n",
              "  0.03769512,\n",
              "  0.009047078,\n",
              "  -0.016961357,\n",
              "  0.010578097,\n",
              "  -0.0045812847,\n",
              "  0.025858505,\n",
              "  -0.06983822,\n",
              "  -0.0015540187,\n",
              "  0.014552897,\n",
              "  0.020480668,\n",
              "  0.04890522,\n",
              "  0.04436032,\n",
              "  -0.0137535585,\n",
              "  -0.011758425,\n",
              "  0.028554687,\n",
              "  0.034880597,\n",
              "  0.016074253,\n",
              "  0.005811369,\n",
              "  0.024092656,\n",
              "  -0.06745602,\n",
              "  -0.014992062,\n",
              "  -0.009297864,\n",
              "  -0.025536213,\n",
              "  -0.00077241444,\n",
              "  0.04694338,\n",
              "  -0.008347593,\n",
              "  0.0033561878,\n",
              "  0.041595824,\n",
              "  0.0076967934,\n",
              "  -0.030719202,\n",
              "  0.016893325,\n",
              "  -0.012160042,\n",
              "  -0.0061670193,\n",
              "  -0.08263306,\n",
              "  -0.017478537,\n",
              "  -0.008123241,\n",
              "  0.0034400742,\n",
              "  -0.027737426,\n",
              "  -0.01237532,\n",
              "  -0.03466614,\n",
              "  0.0643874,\n",
              "  -0.008038767,\n",
              "  -0.034651496,\n",
              "  0.059117883,\n",
              "  0.00475624,\n",
              "  0.009932646,\n",
              "  -0.04194739,\n",
              "  -0.028383443,\n",
              "  0.0504438,\n",
              "  -0.019475708,\n",
              "  0.04780983,\n",
              "  0.055564675,\n",
              "  -0.00031584853,\n",
              "  0.0099988775,\n",
              "  0.029907204,\n",
              "  -0.015757533,\n",
              "  0.010886658,\n",
              "  0.07492535,\n",
              "  -0.03151615,\n",
              "  -0.016033692,\n",
              "  -0.019740222,\n",
              "  -0.003588736,\n",
              "  0.024081541,\n",
              "  -0.027382469,\n",
              "  0.046955176,\n",
              "  0.037322007,\n",
              "  -0.02023512,\n",
              "  -0.032734316,\n",
              "  -0.017579388,\n",
              "  0.032886323,\n",
              "  0.017380089,\n",
              "  0.014535386,\n",
              "  0.021153303,\n",
              "  -0.023898773,\n",
              "  -0.07019639,\n",
              "  0.014245998,\n",
              "  -0.009596892,\n",
              "  0.01000225,\n",
              "  0.021582106,\n",
              "  0.037930585,\n",
              "  0.019922009,\n",
              "  0.09143462,\n",
              "  -0.006376674,\n",
              "  -0.020459104,\n",
              "  -0.0071547753,\n",
              "  -0.03296648,\n",
              "  0.013156819,\n",
              "  -0.058492042,\n",
              "  -0.04543951,\n",
              "  0.071917,\n",
              "  -0.0074261175,\n",
              "  0.02029321,\n",
              "  0.0074217645,\n",
              "  0.011361693,\n",
              "  -0.013487603,\n",
              "  -0.041737273,\n",
              "  0.03736623,\n",
              "  -0.01337041,\n",
              "  0.048313387,\n",
              "  -0.006907955,\n",
              "  0.06655056,\n",
              "  -0.023520961,\n",
              "  -0.027065527,\n",
              "  0.0029429884,\n",
              "  0.010783496,\n",
              "  0.0061046677,\n",
              "  -0.006664861,\n",
              "  0.0263736,\n",
              "  0.012505367,\n",
              "  0.0025366691,\n",
              "  -0.018633252,\n",
              "  -0.023263583,\n",
              "  0.05680022,\n",
              "  0.03173127,\n",
              "  0.016629785,\n",
              "  -0.0051717577,\n",
              "  0.05449998,\n",
              "  0.028534895,\n",
              "  0.0136833275,\n",
              "  0.025178075,\n",
              "  0.015851948,\n",
              "  0.016999032,\n",
              "  -0.0024715154,\n",
              "  0.0081630265,\n",
              "  0.009414808,\n",
              "  0.01796013,\n",
              "  -0.007966241,\n",
              "  -0.045169093,\n",
              "  0.05652869,\n",
              "  -0.024532769,\n",
              "  0.079669125,\n",
              "  0.018309638,\n",
              "  -0.026140317,\n",
              "  0.028072268,\n",
              "  0.03465,\n",
              "  -0.006930882,\n",
              "  -0.024585804,\n",
              "  0.011721978,\n",
              "  0.021883816,\n",
              "  -0.058701966,\n",
              "  0.020795155,\n",
              "  -0.0099482415,\n",
              "  -0.002895562,\n",
              "  -0.0020919817,\n",
              "  -0.018519828,\n",
              "  -0.045245595,\n",
              "  -0.03022019,\n",
              "  0.0038413482,\n",
              "  0.0016043783,\n",
              "  -0.0035489467,\n",
              "  -0.020633966,\n",
              "  -0.0018349856,\n",
              "  -0.01368904,\n",
              "  -0.012627614,\n",
              "  -0.021377292,\n",
              "  0.020669464,\n",
              "  0.014901842,\n",
              "  -0.039516848,\n",
              "  -0.0038436349,\n",
              "  0.020857181,\n",
              "  -0.04150413,\n",
              "  0.06376243,\n",
              "  -0.0003928595,\n",
              "  0.05690966,\n",
              "  0.0129593285,\n",
              "  -0.008163979,\n",
              "  -0.014843889,\n",
              "  0.02432044,\n",
              "  0.015458875,\n",
              "  -0.0040995087,\n",
              "  -0.00531972,\n",
              "  -0.021544976,\n",
              "  0.055595174,\n",
              "  0.01387417,\n",
              "  -0.038996834,\n",
              "  -0.0214864,\n",
              "  -0.029532291,\n",
              "  -0.035090793,\n",
              "  -0.017369559,\n",
              "  0.025355851,\n",
              "  0.003824686,\n",
              "  0.005885343,\n",
              "  -0.0070618954,\n",
              "  0.02950433,\n",
              "  0.013110409,\n",
              "  -0.039437566,\n",
              "  -0.10224025,\n",
              "  -0.014233478,\n",
              "  -0.028835813,\n",
              "  0.003048811,\n",
              "  -0.0052784462,\n",
              "  0.015127126,\n",
              "  0.047107216,\n",
              "  -0.052115593,\n",
              "  0.06589354,\n",
              "  -0.078050405,\n",
              "  0.009398376,\n",
              "  0.0008092549,\n",
              "  -0.02796681,\n",
              "  0.038739078,\n",
              "  -0.022436947,\n",
              "  -0.03769995,\n",
              "  0.019305423,\n",
              "  0.014897552,\n",
              "  -0.011505598,\n",
              "  -0.04351176,\n",
              "  -0.0044094906,\n",
              "  -0.0023350879,\n",
              "  0.00021167938,\n",
              "  -0.006025928,\n",
              "  0.02716689,\n",
              "  -0.049027167,\n",
              "  0.021081125,\n",
              "  0.051549412,\n",
              "  -0.02255372,\n",
              "  -0.0015457448,\n",
              "  0.018564304,\n",
              "  0.010656274,\n",
              "  -0.024513768,\n",
              "  0.04167924,\n",
              "  0.007119747,\n",
              "  -0.02099244,\n",
              "  0.010541077,\n",
              "  0.052136786,\n",
              "  0.018352011,\n",
              "  -0.03898542,\n",
              "  0.07575739,\n",
              "  -0.040208854,\n",
              "  -0.01607118,\n",
              "  0.05402094,\n",
              "  0.02371712,\n",
              "  -0.0318583,\n",
              "  -0.032484435,\n",
              "  0.035460398,\n",
              "  -0.023447175,\n",
              "  -0.008730115,\n",
              "  0.039209794,\n",
              "  -0.03573278,\n",
              "  -0.0513359,\n",
              "  0.0048044124,\n",
              "  -0.05729078,\n",
              "  0.0048382543,\n",
              "  -0.027352331,\n",
              "  0.044448912,\n",
              "  -0.006448664,\n",
              "  -0.027387153,\n",
              "  0.011546101,\n",
              "  0.044653505,\n",
              "  0.03376712,\n",
              "  -0.022989623,\n",
              "  -0.023643875,\n",
              "  0.009231472,\n",
              "  0.05495298,\n",
              "  0.049281925,\n",
              "  0.029892156,\n",
              "  -0.02704056,\n",
              "  0.026554333,\n",
              "  0.023819864,\n",
              "  -0.00973637,\n",
              "  0.0037274845,\n",
              "  0.03181062,\n",
              "  0.015335569,\n",
              "  -0.020901635,\n",
              "  -0.021788256,\n",
              "  -0.06170201,\n",
              "  0.0017851259,\n",
              "  0.021283107,\n",
              "  0.084311284,\n",
              "  -0.045992393,\n",
              "  -0.024755564,\n",
              "  0.0005011732,\n",
              "  -0.036614094,\n",
              "  -0.033821356,\n",
              "  0.029556422,\n",
              "  -0.001534007,\n",
              "  0.015472785,\n",
              "  0.03163294,\n",
              "  -0.048191715,\n",
              "  0.04950327,\n",
              "  -0.05185118,\n",
              "  -0.061203044,\n",
              "  -0.001973536,\n",
              "  -0.013100074,\n",
              "  -0.05760203,\n",
              "  0.0075447066,\n",
              "  0.041262984,\n",
              "  -0.0053429846,\n",
              "  -0.003509607,\n",
              "  -0.008535974,\n",
              "  -0.084441744,\n",
              "  0.028880242,\n",
              "  -0.010176243,\n",
              "  0.04894968,\n",
              "  0.041374855,\n",
              "  0.018863447,\n",
              "  -0.0046489527,\n",
              "  0.023346595,\n",
              "  -0.009243764,\n",
              "  0.010172647,\n",
              "  0.026920192,\n",
              "  0.018600948,\n",
              "  -0.0028697974,\n",
              "  -0.03889172,\n",
              "  -0.0047684573,\n",
              "  0.05015922,\n",
              "  0.0035100444,\n",
              "  -0.03177088,\n",
              "  -0.070479125,\n",
              "  0.021856574,\n",
              "  -0.040042367,\n",
              "  0.05003176,\n",
              "  0.06601648,\n",
              "  0.015189354,\n",
              "  -0.03226619,\n",
              "  0.052379232,\n",
              "  -0.01252433,\n",
              "  -0.02204321,\n",
              "  -0.023669206,\n",
              "  0.02325206,\n",
              "  -0.0033283767,\n",
              "  -0.012253982,\n",
              "  0.065073304,\n",
              "  -0.043772303,\n",
              "  -0.050255094,\n",
              "  -0.045141216,\n",
              "  -0.020505674,\n",
              "  -0.015791064,\n",
              "  -0.0536492,\n",
              "  -0.013423865,\n",
              "  -0.04917738,\n",
              "  -0.021504156,\n",
              "  -0.078644216,\n",
              "  -2.4754061e-05,\n",
              "  0.036258623,\n",
              "  0.069118276,\n",
              "  0.040980436,\n",
              "  -0.0016522766,\n",
              "  -0.017353958,\n",
              "  -0.006596057,\n",
              "  0.04507032,\n",
              "  0.051912732,\n",
              "  -0.02920979,\n",
              "  0.017322531,\n",
              "  -0.02120513,\n",
              "  -0.0079615,\n",
              "  -0.08787053,\n",
              "  -0.00019343989,\n",
              "  0.012567655,\n",
              "  -0.03589679],\n",
              " [-0.00966427,\n",
              "  0.030931212,\n",
              "  -0.06882039,\n",
              "  -0.023562329,\n",
              "  -0.012639077,\n",
              "  0.011706099,\n",
              "  0.050656304,\n",
              "  0.032964673,\n",
              "  -0.030153923,\n",
              "  0.013603598,\n",
              "  -0.014837082,\n",
              "  0.008510862,\n",
              "  0.03533983,\n",
              "  -0.025198981,\n",
              "  -0.0011285022,\n",
              "  -0.10442935,\n",
              "  0.047623068,\n",
              "  -0.0090080965,\n",
              "  -0.08277321,\n",
              "  0.014584065,\n",
              "  0.005561778,\n",
              "  -0.023414642,\n",
              "  0.0075211404,\n",
              "  -0.04809664,\n",
              "  -0.040195305,\n",
              "  -0.009933364,\n",
              "  0.045276985,\n",
              "  -0.038713202,\n",
              "  -0.013725808,\n",
              "  -0.019009782,\n",
              "  0.07614407,\n",
              "  0.07347804,\n",
              "  0.015828716,\n",
              "  -0.05324889,\n",
              "  0.024699097,\n",
              "  0.0020504075,\n",
              "  0.007321242,\n",
              "  0.026272524,\n",
              "  0.067218654,\n",
              "  -0.030696709,\n",
              "  -0.055731606,\n",
              "  -0.01562758,\n",
              "  -0.05684959,\n",
              "  0.08414856,\n",
              "  -0.025612356,\n",
              "  0.0041105286,\n",
              "  0.008919511,\n",
              "  0.03980723,\n",
              "  -0.01614992,\n",
              "  0.031148994,\n",
              "  0.040355545,\n",
              "  0.0102580385,\n",
              "  -0.008013579,\n",
              "  -0.020251341,\n",
              "  -0.04367321,\n",
              "  -0.064677246,\n",
              "  -0.0050762366,\n",
              "  -0.0035353017,\n",
              "  0.053179763,\n",
              "  -0.022719324,\n",
              "  -0.035255987,\n",
              "  -0.03126904,\n",
              "  -0.0161395,\n",
              "  -0.024969576,\n",
              "  -0.03815435,\n",
              "  -0.0030686187,\n",
              "  -0.026038038,\n",
              "  0.04542225,\n",
              "  -0.090437904,\n",
              "  0.03810512,\n",
              "  0.031946205,\n",
              "  -0.0019053972,\n",
              "  -0.067232005,\n",
              "  0.024975093,\n",
              "  0.013747222,\n",
              "  0.00741205,\n",
              "  0.022397818,\n",
              "  -0.002988564,\n",
              "  -0.043123435,\n",
              "  0.009489262,\n",
              "  -0.023998212,\n",
              "  0.030819058,\n",
              "  0.05226745,\n",
              "  0.041605137,\n",
              "  -0.0058395625,\n",
              "  -0.049331058,\n",
              "  0.011557444,\n",
              "  -0.035253365,\n",
              "  -0.10930957,\n",
              "  -0.024341356,\n",
              "  0.029002193,\n",
              "  -0.013836986,\n",
              "  0.029714216,\n",
              "  0.017535174,\n",
              "  0.050088014,\n",
              "  -0.07435695,\n",
              "  -0.04245983,\n",
              "  -0.076099955,\n",
              "  0.012286103,\n",
              "  0.07913419,\n",
              "  0.054136977,\n",
              "  0.010303309,\n",
              "  0.011509688,\n",
              "  -0.03564116,\n",
              "  0.0478576,\n",
              "  0.1075017,\n",
              "  -0.031648833,\n",
              "  -0.008518733,\n",
              "  -0.08560467,\n",
              "  0.021949194,\n",
              "  0.004953995,\n",
              "  -0.034071043,\n",
              "  0.023812117,\n",
              "  -0.039680883,\n",
              "  0.016490297,\n",
              "  -0.044254422,\n",
              "  -0.040673994,\n",
              "  0.024845507,\n",
              "  -0.02902985,\n",
              "  -0.014194606,\n",
              "  -0.011615183,\n",
              "  0.049194302,\n",
              "  0.0181311,\n",
              "  0.011959901,\n",
              "  0.05211457,\n",
              "  0.055218764,\n",
              "  0.01873212,\n",
              "  -0.041999646,\n",
              "  -0.02570464,\n",
              "  0.0069287955,\n",
              "  0.14567035,\n",
              "  -0.09110786,\n",
              "  0.013670172,\n",
              "  0.013064959,\n",
              "  -0.028812824,\n",
              "  -0.016679883,\n",
              "  0.09117056,\n",
              "  -0.033416722,\n",
              "  0.026743904,\n",
              "  0.0361672,\n",
              "  0.020488063,\n",
              "  -0.006074147,\n",
              "  -0.09829552,\n",
              "  0.032202497,\n",
              "  0.040260665,\n",
              "  -0.06087115,\n",
              "  0.05336827,\n",
              "  0.02452828,\n",
              "  -0.042712897,\n",
              "  -0.0025814362,\n",
              "  0.010159302,\n",
              "  0.022729618,\n",
              "  -0.010721245,\n",
              "  0.01331748,\n",
              "  -0.03470981,\n",
              "  -0.014589032,\n",
              "  0.058330636,\n",
              "  -0.028722264,\n",
              "  0.08954171,\n",
              "  -0.0030616098,\n",
              "  -0.01187223,\n",
              "  -0.105825186,\n",
              "  0.044906735,\n",
              "  -0.020994008,\n",
              "  -0.015928438,\n",
              "  -0.038151763,\n",
              "  0.046213124,\n",
              "  -0.047557216,\n",
              "  0.03947786,\n",
              "  0.019142043,\n",
              "  -0.0101097785,\n",
              "  -0.0058513177,\n",
              "  -0.016617846,\n",
              "  -0.020814171,\n",
              "  -0.016652822,\n",
              "  -0.0031175986,\n",
              "  0.019798363,\n",
              "  -0.04275964,\n",
              "  -0.020009717,\n",
              "  -0.00085922435,\n",
              "  0.114571646,\n",
              "  0.043730576,\n",
              "  0.017049897,\n",
              "  -0.07440002,\n",
              "  0.008380452,\n",
              "  0.004159044,\n",
              "  0.0012696557,\n",
              "  0.018546164,\n",
              "  0.03286254,\n",
              "  0.08201249,\n",
              "  -0.035561323,\n",
              "  -0.017216017,\n",
              "  0.01661555,\n",
              "  0.002583202,\n",
              "  0.05352139,\n",
              "  -0.020747155,\n",
              "  -0.0012683121,\n",
              "  -0.010094952,\n",
              "  -0.022129128,\n",
              "  -0.03326438,\n",
              "  0.030182682,\n",
              "  -0.016583627,\n",
              "  0.026935503,\n",
              "  -0.05104353,\n",
              "  -0.016721075,\n",
              "  -0.037230235,\n",
              "  -0.040957425,\n",
              "  -0.035171483,\n",
              "  0.05259733,\n",
              "  0.024002766,\n",
              "  -0.028166221,\n",
              "  -0.015008336,\n",
              "  -0.00071511365,\n",
              "  -0.014001845,\n",
              "  0.0050752317,\n",
              "  0.0108496,\n",
              "  0.03826731,\n",
              "  -0.015778715,\n",
              "  0.055282142,\n",
              "  0.031286173,\n",
              "  -0.026866434,\n",
              "  -0.04171574,\n",
              "  -0.03588182,\n",
              "  -0.021027476,\n",
              "  0.027762013,\n",
              "  0.061689258,\n",
              "  -0.020315088,\n",
              "  -0.0525946,\n",
              "  0.026899796,\n",
              "  -0.042993713,\n",
              "  0.021647187,\n",
              "  -0.00599902,\n",
              "  0.0032696847,\n",
              "  0.00533419,\n",
              "  0.033115853,\n",
              "  0.03243283,\n",
              "  -0.023485702,\n",
              "  -0.036789786,\n",
              "  -0.029130373,\n",
              "  -0.031438656,\n",
              "  -0.012532979,\n",
              "  0.041013807,\n",
              "  0.006199427,\n",
              "  -0.011604889,\n",
              "  0.029144403,\n",
              "  0.048535354,\n",
              "  -0.026717013,\n",
              "  0.048812892,\n",
              "  -0.04784331,\n",
              "  -0.08249016,\n",
              "  -0.029600758,\n",
              "  0.013921806,\n",
              "  -0.07463823,\n",
              "  -0.054253902,\n",
              "  0.010612926,\n",
              "  -0.03103928,\n",
              "  0.014459394,\n",
              "  0.0134899225,\n",
              "  -0.012888754,\n",
              "  0.018036742,\n",
              "  0.00926372,\n",
              "  -0.08057068,\n",
              "  -0.010062377,\n",
              "  -0.07238487,\n",
              "  -0.017761592,\n",
              "  -0.07798509,\n",
              "  -0.053557206,\n",
              "  -0.017534714,\n",
              "  0.02378468,\n",
              "  -0.052604973,\n",
              "  0.043708403,\n",
              "  0.006762731,\n",
              "  -0.024167178,\n",
              "  -0.039770328,\n",
              "  0.037257098,\n",
              "  0.060861226,\n",
              "  0.010823677,\n",
              "  0.0022168315,\n",
              "  -0.008114964,\n",
              "  -0.007616868,\n",
              "  -0.01513139,\n",
              "  0.013882358,\n",
              "  0.009818275,\n",
              "  0.00013346325,\n",
              "  0.036858387,\n",
              "  -0.08724789,\n",
              "  -0.028807357,\n",
              "  -0.014386862,\n",
              "  -0.032290738,\n",
              "  -0.0015963642,\n",
              "  0.036649663,\n",
              "  0.042209763,\n",
              "  -0.011430846,\n",
              "  -0.049231555,\n",
              "  0.041319877,\n",
              "  0.033125397,\n",
              "  0.06650588,\n",
              "  0.01018296,\n",
              "  -0.002378946,\n",
              "  -0.014680302,\n",
              "  0.06661789,\n",
              "  0.062018342,\n",
              "  0.004377079,\n",
              "  0.052884553,\n",
              "  0.024368186,\n",
              "  0.036201008,\n",
              "  0.05385686,\n",
              "  -0.052936845,\n",
              "  0.021985877,\n",
              "  0.0016701922,\n",
              "  -0.02052935,\n",
              "  -0.011671236,\n",
              "  -0.029565888,\n",
              "  -0.047592446,\n",
              "  -0.049766432,\n",
              "  0.009396901,\n",
              "  -0.1298805,\n",
              "  -0.0015028577,\n",
              "  -0.06176096,\n",
              "  -0.006350996,\n",
              "  -0.010001716,\n",
              "  0.023554398,\n",
              "  0.017477887,\n",
              "  -0.037217714,\n",
              "  0.043541647,\n",
              "  -0.035173576,\n",
              "  -0.024461603,\n",
              "  0.012068744,\n",
              "  0.047830082,\n",
              "  -0.03135324,\n",
              "  0.039121136,\n",
              "  0.055224825,\n",
              "  -0.03992537,\n",
              "  -0.051869966,\n",
              "  -0.0046215993,\n",
              "  -0.0083434265,\n",
              "  -0.021493599,\n",
              "  0.0240354,\n",
              "  0.033891413,\n",
              "  0.015314049,\n",
              "  -0.007642157,\n",
              "  0.016443606,\n",
              "  0.031395484,\n",
              "  0.057711855,\n",
              "  0.019583805,\n",
              "  -0.016987154,\n",
              "  -0.022328235,\n",
              "  -0.0072493698,\n",
              "  0.040488567,\n",
              "  -0.008658282,\n",
              "  -0.0028178617,\n",
              "  0.0145619875,\n",
              "  0.027014816,\n",
              "  0.026128689,\n",
              "  -0.020123204,\n",
              "  -0.009531184,\n",
              "  0.02912258,\n",
              "  -0.0068935477,\n",
              "  0.026183246,\n",
              "  -0.00839736,\n",
              "  0.0013371039,\n",
              "  0.006093873,\n",
              "  0.023985563,\n",
              "  -4.1321586e-05,\n",
              "  -0.03281602,\n",
              "  -0.060568135,\n",
              "  0.0021805477,\n",
              "  0.0075246487,\n",
              "  0.0014551079,\n",
              "  -0.016191037,\n",
              "  0.03864786,\n",
              "  -0.04894996,\n",
              "  0.00496119,\n",
              "  -0.017767018,\n",
              "  0.026397277,\n",
              "  -0.02989917,\n",
              "  0.017959522,\n",
              "  0.038936604,\n",
              "  0.06944826,\n",
              "  -0.046899036,\n",
              "  -0.03806075,\n",
              "  -0.046760757,\n",
              "  0.008669668,\n",
              "  -0.024511768,\n",
              "  -0.06219747,\n",
              "  0.07734601,\n",
              "  -0.025050325,\n",
              "  0.0145582305,\n",
              "  0.026607675,\n",
              "  0.026705986,\n",
              "  -0.023088176,\n",
              "  0.026288176,\n",
              "  0.0671798,\n",
              "  0.0075294473,\n",
              "  0.0104928715,\n",
              "  -0.015304344,\n",
              "  -0.06490164,\n",
              "  -0.014570236,\n",
              "  0.010453915,\n",
              "  0.030984553,\n",
              "  -0.016282892,\n",
              "  0.0011112841,\n",
              "  0.08648566,\n",
              "  -0.027982317,\n",
              "  8.898016e-05,\n",
              "  -0.022646448,\n",
              "  0.06127759,\n",
              "  0.002204987,\n",
              "  -0.0010819279,\n",
              "  0.017052514,\n",
              "  -0.028535562,\n",
              "  0.0058179074,\n",
              "  -0.039443057,\n",
              "  0.0069532567,\n",
              "  -0.061526965,\n",
              "  0.028799355,\n",
              "  0.021184277,\n",
              "  0.006546988,\n",
              "  -0.0050972807,\n",
              "  0.081475236,\n",
              "  0.0016501761,\n",
              "  0.004220769,\n",
              "  0.01552024,\n",
              "  -0.015997598,\n",
              "  0.0421107,\n",
              "  -0.0580317,\n",
              "  -0.03304376,\n",
              "  0.016662395,\n",
              "  0.031416684,\n",
              "  -0.001786668,\n",
              "  0.01610985,\n",
              "  -0.045099378,\n",
              "  -0.0068384884,\n",
              "  0.0062602763,\n",
              "  0.020452173,\n",
              "  0.003483059,\n",
              "  0.02405543,\n",
              "  -0.020086361,\n",
              "  -0.040959246,\n",
              "  -0.050224815,\n",
              "  0.012461686,\n",
              "  -0.026358964,\n",
              "  -0.020951817,\n",
              "  0.08156911,\n",
              "  -0.035970878,\n",
              "  0.023934364,\n",
              "  0.044744376,\n",
              "  0.017354548,\n",
              "  -0.016999325,\n",
              "  0.027871095,\n",
              "  -0.0010269883,\n",
              "  -0.024121698,\n",
              "  -0.07125911,\n",
              "  -0.03297836,\n",
              "  -0.036456637,\n",
              "  0.012090182,\n",
              "  0.017560914,\n",
              "  -0.0133243045,\n",
              "  -0.01881424,\n",
              "  0.05597523,\n",
              "  -0.019147513,\n",
              "  -0.038944896,\n",
              "  0.037304856,\n",
              "  0.0037644545,\n",
              "  0.028541937,\n",
              "  -0.044183202,\n",
              "  -0.018337833,\n",
              "  0.08013108,\n",
              "  -0.018319884,\n",
              "  -0.01201188,\n",
              "  0.08257584,\n",
              "  6.0003378e-05,\n",
              "  0.0058404324,\n",
              "  -0.01405489,\n",
              "  -0.03896821,\n",
              "  0.02257518,\n",
              "  0.052925665,\n",
              "  0.007479951,\n",
              "  0.0039931256,\n",
              "  -0.023147123,\n",
              "  0.02565546,\n",
              "  0.01050507,\n",
              "  -0.003315016,\n",
              "  0.049610235,\n",
              "  0.0570205,\n",
              "  -0.05280735,\n",
              "  -0.06088215,\n",
              "  -0.0027822007,\n",
              "  0.04048127,\n",
              "  0.027548343,\n",
              "  -0.0072230813,\n",
              "  0.01021907,\n",
              "  -0.050190333,\n",
              "  -0.03967466,\n",
              "  0.053275432,\n",
              "  0.008627333,\n",
              "  0.027516048,\n",
              "  0.0044980585,\n",
              "  0.022248186,\n",
              "  0.024811884,\n",
              "  0.08783037,\n",
              "  -0.021402486,\n",
              "  -0.0070359074,\n",
              "  -0.059886824,\n",
              "  -0.011119658,\n",
              "  -0.02577626,\n",
              "  -0.0050215293,\n",
              "  -0.00071427267,\n",
              "  0.06284111,\n",
              "  0.005702479,\n",
              "  0.018829232,\n",
              "  -0.017981572,\n",
              "  0.011685083,\n",
              "  -0.008475608,\n",
              "  -0.0072114486,\n",
              "  0.027420871,\n",
              "  -0.010731461,\n",
              "  0.028349416,\n",
              "  -0.019017551,\n",
              "  -0.008192707,\n",
              "  -0.025420854,\n",
              "  -0.037973758,\n",
              "  -0.0062428312,\n",
              "  0.019983977,\n",
              "  -0.0042288452,\n",
              "  -0.01409289,\n",
              "  0.0059563685,\n",
              "  -0.016850641,\n",
              "  0.007894139,\n",
              "  -0.028275963,\n",
              "  -0.054886315,\n",
              "  0.086405985,\n",
              "  0.03254577,\n",
              "  0.018524654,\n",
              "  -0.030513115,\n",
              "  0.047035974,\n",
              "  0.007799723,\n",
              "  0.0058364873,\n",
              "  0.022218848,\n",
              "  -0.03724352,\n",
              "  -0.0053025163,\n",
              "  -0.030912424,\n",
              "  0.016183158,\n",
              "  0.009655813,\n",
              "  0.009318239,\n",
              "  0.020422969,\n",
              "  -0.022334322,\n",
              "  0.082880475,\n",
              "  -0.015884597,\n",
              "  0.048643284,\n",
              "  0.041077025,\n",
              "  -0.024957677,\n",
              "  0.05407627,\n",
              "  0.04977423,\n",
              "  -0.009755784,\n",
              "  -0.0105764195,\n",
              "  0.047101326,\n",
              "  0.0013709753,\n",
              "  -0.0504973,\n",
              "  0.014329951,\n",
              "  0.002670297,\n",
              "  0.010331951,\n",
              "  -0.032656264,\n",
              "  -0.024425808,\n",
              "  0.01620976,\n",
              "  -0.05496575,\n",
              "  -0.020047957,\n",
              "  0.036579143,\n",
              "  -0.00993189,\n",
              "  -0.023616482,\n",
              "  -0.015212392,\n",
              "  -0.008846142,\n",
              "  -0.029077383,\n",
              "  -0.023723615,\n",
              "  0.002412005,\n",
              "  -0.015103284,\n",
              "  -0.023356883,\n",
              "  -0.002169104,\n",
              "  0.042455953,\n",
              "  -0.030527638,\n",
              "  0.061327185,\n",
              "  -0.02174378,\n",
              "  0.059381656,\n",
              "  -0.015733743,\n",
              "  0.00659256,\n",
              "  -0.009808234,\n",
              "  -0.008324563,\n",
              "  0.007248419,\n",
              "  0.045274917,\n",
              "  -0.023328228,\n",
              "  -0.028885433,\n",
              "  0.015549834,\n",
              "  -0.008362249,\n",
              "  -0.0432193,\n",
              "  -0.015481617,\n",
              "  -0.016852649,\n",
              "  -0.046727736,\n",
              "  0.007331624,\n",
              "  0.021192135,\n",
              "  0.012341429,\n",
              "  0.03144759,\n",
              "  -0.009122386,\n",
              "  0.028049689,\n",
              "  0.019505652,\n",
              "  -0.046432503,\n",
              "  -0.10162827,\n",
              "  -0.046915494,\n",
              "  0.005401229,\n",
              "  -0.0036123332,\n",
              "  0.015804168,\n",
              "  0.014144952,\n",
              "  0.016125115,\n",
              "  -0.026644161,\n",
              "  0.03233253,\n",
              "  -0.09303083,\n",
              "  -0.015953083,\n",
              "  -0.032159995,\n",
              "  0.0008144198,\n",
              "  0.017861111,\n",
              "  -0.00048387834,\n",
              "  -0.013663496,\n",
              "  0.0090746265,\n",
              "  0.0039206217,\n",
              "  -0.066072494,\n",
              "  -0.044651765,\n",
              "  -0.018150078,\n",
              "  0.0067870137,\n",
              "  0.010647894,\n",
              "  -0.02494141,\n",
              "  0.014870427,\n",
              "  -0.012069385,\n",
              "  0.03146825,\n",
              "  0.036879238,\n",
              "  -0.05423263,\n",
              "  -0.026231812,\n",
              "  0.038457036,\n",
              "  0.039663773,\n",
              "  -0.052487515,\n",
              "  0.028450552,\n",
              "  -0.028967278,\n",
              "  0.011602866,\n",
              "  -0.0022964473,\n",
              "  0.04217767,\n",
              "  0.0041132863,\n",
              "  -0.023909992,\n",
              "  0.034173198,\n",
              "  -0.009210267,\n",
              "  -0.024276806,\n",
              "  0.037743006,\n",
              "  0.023407908,\n",
              "  -0.0119633945,\n",
              "  -0.004234705,\n",
              "  -0.010193237,\n",
              "  0.0030770174,\n",
              "  -0.028672988,\n",
              "  -0.007266546,\n",
              "  -0.013737169,\n",
              "  -0.022103358,\n",
              "  0.0010331998,\n",
              "  -0.048373263,\n",
              "  -0.020149287,\n",
              "  -0.04053532,\n",
              "  0.034382887,\n",
              "  0.029738303,\n",
              "  -0.012903254,\n",
              "  -0.00074233476,\n",
              "  0.016807918,\n",
              "  0.01582527,\n",
              "  -0.009661605,\n",
              "  0.004978162,\n",
              "  0.032318957,\n",
              "  0.004229548,\n",
              "  0.037745968,\n",
              "  0.03836435,\n",
              "  -0.043823708,\n",
              "  -0.009412134,\n",
              "  0.007343415,\n",
              "  -0.02744678,\n",
              "  0.01697003,\n",
              "  0.026742699,\n",
              "  -0.022670517,\n",
              "  -0.008798384,\n",
              "  -0.022811525,\n",
              "  -0.003463597,\n",
              "  0.02139913,\n",
              "  -0.0046774526,\n",
              "  0.059343033,\n",
              "  -0.0484059,\n",
              "  -0.0017529703,\n",
              "  -0.0017459268,\n",
              "  -0.040462818,\n",
              "  -0.020836046,\n",
              "  0.0028280402,\n",
              "  0.03948207,\n",
              "  -0.019504376,\n",
              "  -0.0153103275,\n",
              "  -0.055629764,\n",
              "  0.030633241,\n",
              "  -0.06336509,\n",
              "  -0.03344549,\n",
              "  -0.009404641,\n",
              "  -0.007607099,\n",
              "  -0.07189058,\n",
              "  -0.009847618,\n",
              "  0.018610792,\n",
              "  -0.0070192493,\n",
              "  0.03360688,\n",
              "  0.009598062,\n",
              "  -0.09042645,\n",
              "  0.019137708,\n",
              "  -0.020264717,\n",
              "  0.041359674,\n",
              "  0.025128504,\n",
              "  0.051294137,\n",
              "  0.015151071,\n",
              "  -0.008056724,\n",
              "  -0.00050702493,\n",
              "  -0.0021223554,\n",
              "  0.024597183,\n",
              "  0.00030790898,\n",
              "  -0.020997778,\n",
              "  -0.0103677595,\n",
              "  -0.008656089,\n",
              "  0.055157255,\n",
              "  -0.008606672,\n",
              "  -0.04007432,\n",
              "  -0.057348598,\n",
              "  0.011380765,\n",
              "  -0.016848262,\n",
              "  0.02966969,\n",
              "  0.022143785,\n",
              "  -0.026330912,\n",
              "  -0.022201499,\n",
              "  0.07997971,\n",
              "  0.01698162,\n",
              "  -0.027453875,\n",
              "  -0.02376561,\n",
              "  0.055857163,\n",
              "  -0.057881072,\n",
              "  -0.025845345,\n",
              "  0.018051405,\n",
              "  -0.03022062,\n",
              "  -0.03595792,\n",
              "  -0.024529804,\n",
              "  0.01393644,\n",
              "  0.014485015,\n",
              "  -0.033256307,\n",
              "  -0.00688556,\n",
              "  -0.018694503,\n",
              "  -0.033869088,\n",
              "  -0.05208234,\n",
              "  0.04879945,\n",
              "  0.04551856,\n",
              "  0.00479283,\n",
              "  0.012296575,\n",
              "  0.0042925,\n",
              "  0.0037068764,\n",
              "  0.016031113,\n",
              "  -0.0002817148,\n",
              "  0.034206074,\n",
              "  -0.023933481,\n",
              "  0.063943624,\n",
              "  -0.03562693,\n",
              "  -0.01972849,\n",
              "  -0.08103856,\n",
              "  -0.061782993,\n",
              "  0.023040297,\n",
              "  -0.03481756],\n",
              " [0.022403503,\n",
              "  0.022988817,\n",
              "  -0.08209265,\n",
              "  -0.020458775,\n",
              "  -0.02745933,\n",
              "  -0.0073366556,\n",
              "  0.034973636,\n",
              "  0.06965054,\n",
              "  -0.0024817064,\n",
              "  0.03606197,\n",
              "  0.0040355423,\n",
              "  0.027135227,\n",
              "  0.059514757,\n",
              "  0.015584991,\n",
              "  0.016784323,\n",
              "  -0.12630579,\n",
              "  0.071062274,\n",
              "  0.01141066,\n",
              "  -0.06635742,\n",
              "  0.022415614,\n",
              "  0.0021980826,\n",
              "  -0.034118038,\n",
              "  0.02608538,\n",
              "  -0.047125123,\n",
              "  -0.03617595,\n",
              "  -0.003822281,\n",
              "  0.026779158,\n",
              "  -0.07079312,\n",
              "  -0.054096073,\n",
              "  -0.0016674981,\n",
              "  0.071613595,\n",
              "  0.068984956,\n",
              "  0.028341781,\n",
              "  -0.038684294,\n",
              "  0.047786992,\n",
              "  0.016816527,\n",
              "  0.00066313887,\n",
              "  0.033762198,\n",
              "  0.027494775,\n",
              "  -0.034596846,\n",
              "  -0.05901258,\n",
              "  -0.013624509,\n",
              "  -0.022431333,\n",
              "  0.046003424,\n",
              "  -0.05418631,\n",
              "  -0.00796463,\n",
              "  -0.0022686778,\n",
              "  0.042894065,\n",
              "  0.016210426,\n",
              "  0.018488877,\n",
              "  0.040590532,\n",
              "  0.012537312,\n",
              "  -0.020902539,\n",
              "  0.019664561,\n",
              "  -0.004547295,\n",
              "  -0.058313943,\n",
              "  0.015252362,\n",
              "  0.0007916499,\n",
              "  0.054291207,\n",
              "  -0.011039042,\n",
              "  -0.036621466,\n",
              "  -0.037499823,\n",
              "  -0.037260834,\n",
              "  -0.020433402,\n",
              "  -0.039642766,\n",
              "  0.008778571,\n",
              "  -0.016867602,\n",
              "  0.029087957,\n",
              "  -0.08211089,\n",
              "  0.051923122,\n",
              "  0.0014310187,\n",
              "  0.01552472,\n",
              "  -0.050977014,\n",
              "  0.01849559,\n",
              "  -0.030132614,\n",
              "  0.003944759,\n",
              "  0.03476986,\n",
              "  -0.004839872,\n",
              "  -0.012030259,\n",
              "  0.013264069,\n",
              "  -0.030366793,\n",
              "  0.028636284,\n",
              "  0.104254864,\n",
              "  0.011045239,\n",
              "  0.016832784,\n",
              "  -0.002560774,\n",
              "  0.0062494255,\n",
              "  -0.03283241,\n",
              "  -0.050102603,\n",
              "  0.016476737,\n",
              "  0.02685127,\n",
              "  0.013440201,\n",
              "  0.031860806,\n",
              "  0.007965067,\n",
              "  0.046241034,\n",
              "  -0.045536198,\n",
              "  -0.0021471404,\n",
              "  -0.07979212,\n",
              "  0.024050511,\n",
              "  0.09821304,\n",
              "  0.028056307,\n",
              "  0.0031609258,\n",
              "  0.008218343,\n",
              "  -0.03020513,\n",
              "  0.04502545,\n",
              "  0.09470302,\n",
              "  -0.05787566,\n",
              "  -0.06599502,\n",
              "  -0.05271341,\n",
              "  0.017794197,\n",
              "  -0.0027468181,\n",
              "  -0.052810885,\n",
              "  0.019899879,\n",
              "  -0.0028904658,\n",
              "  0.056819383,\n",
              "  -0.037496027,\n",
              "  -0.0222385,\n",
              "  -0.002975352,\n",
              "  -0.056389667,\n",
              "  0.037810434,\n",
              "  -0.012462253,\n",
              "  0.0074807424,\n",
              "  -0.015267613,\n",
              "  0.05481231,\n",
              "  0.045485016,\n",
              "  -0.00019721089,\n",
              "  0.023071148,\n",
              "  -0.025652332,\n",
              "  -0.03799065,\n",
              "  0.014479148,\n",
              "  0.09907224,\n",
              "  -0.069758914,\n",
              "  -0.021909075,\n",
              "  -0.0035149476,\n",
              "  -0.014267431,\n",
              "  -0.039892536,\n",
              "  0.065153696,\n",
              "  -0.0026504293,\n",
              "  0.009865901,\n",
              "  0.0030138893,\n",
              "  0.034212697,\n",
              "  -0.01734058,\n",
              "  -0.10300446,\n",
              "  0.054510117,\n",
              "  0.017546827,\n",
              "  -0.019341733,\n",
              "  0.04563601,\n",
              "  0.04465983,\n",
              "  -0.017829133,\n",
              "  0.0016537642,\n",
              "  0.014156828,\n",
              "  0.032796495,\n",
              "  -0.026187152,\n",
              "  0.01324187,\n",
              "  -0.03430663,\n",
              "  -0.024804253,\n",
              "  0.09924435,\n",
              "  -0.015778631,\n",
              "  0.099652976,\n",
              "  0.018581823,\n",
              "  0.014273097,\n",
              "  -0.07533237,\n",
              "  0.024960946,\n",
              "  -0.017016869,\n",
              "  -0.036855556,\n",
              "  -0.03648692,\n",
              "  0.013217654,\n",
              "  -0.07792074,\n",
              "  -0.012226083,\n",
              "  -0.021812312,\n",
              "  -0.0028902565,\n",
              "  0.014764485,\n",
              "  -0.036834627,\n",
              "  -0.028154913,\n",
              "  -0.0077255517,\n",
              "  0.009361563,\n",
              "  0.01509439,\n",
              "  -0.050959576,\n",
              "  -0.032923922,\n",
              "  -0.0061963336,\n",
              "  0.11681474,\n",
              "  0.02570805,\n",
              "  0.026165787,\n",
              "  -0.10495892,\n",
              "  0.004528893,\n",
              "  0.033897717,\n",
              "  0.032866072,\n",
              "  0.021576077,\n",
              "  0.02779303,\n",
              "  0.07052736,\n",
              "  -0.043259267,\n",
              "  -0.020681703,\n",
              "  -0.00327815,\n",
              "  0.037093453,\n",
              "  0.025279323,\n",
              "  -0.019523758,\n",
              "  -0.0026696427,\n",
              "  -0.009295769,\n",
              "  -0.06097727,\n",
              "  -0.029083185,\n",
              "  0.055922903,\n",
              "  -0.025890373,\n",
              "  0.016199375,\n",
              "  -0.049345214,\n",
              "  0.006756458,\n",
              "  -0.044729106,\n",
              "  -0.057162274,\n",
              "  -0.064629294,\n",
              "  0.031034796,\n",
              "  0.021221317,\n",
              "  -0.00018972745,\n",
              "  -0.026332645,\n",
              "  0.018027423,\n",
              "  0.02447567,\n",
              "  0.02227279,\n",
              "  0.006656,\n",
              "  0.058011267,\n",
              "  -0.014403019,\n",
              "  0.09753121,\n",
              "  0.010128232,\n",
              "  -0.013708951,\n",
              "  -0.015630635,\n",
              "  -0.023344234,\n",
              "  -0.0018852561,\n",
              "  0.0031413145,\n",
              "  0.02619438,\n",
              "  -0.025457095,\n",
              "  -0.04088829,\n",
              "  0.01949671,\n",
              "  -0.06274227,\n",
              "  -0.015124478,\n",
              "  -0.02480356,\n",
              "  -0.007603347,\n",
              "  0.0049282857,\n",
              "  0.03860244,\n",
              "  0.015147271,\n",
              "  -0.01036262,\n",
              "  -0.057263944,\n",
              "  -0.01890308,\n",
              "  -0.021822339,\n",
              "  0.0018767026,\n",
              "  0.06371246,\n",
              "  -0.00797734,\n",
              "  0.030296322,\n",
              "  0.06709061,\n",
              "  0.038002696,\n",
              "  -0.014472218,\n",
              "  0.046090536,\n",
              "  -0.08091731,\n",
              "  -0.0809893,\n",
              "  -0.047778483,\n",
              "  -0.001372123,\n",
              "  -0.062969945,\n",
              "  -0.051710095,\n",
              "  0.009054779,\n",
              "  -0.026495887,\n",
              "  0.029619494,\n",
              "  -0.012752391,\n",
              "  0.02194634,\n",
              "  0.026047146,\n",
              "  0.004702625,\n",
              "  -0.08306193,\n",
              "  -0.0234359,\n",
              "  -0.054657202,\n",
              "  0.004314359,\n",
              "  -0.07556442,\n",
              "  -0.019266993,\n",
              "  -0.05957914,\n",
              "  0.04504483,\n",
              "  -0.0334979,\n",
              "  0.022580894,\n",
              "  -0.0021280097,\n",
              "  -0.03540203,\n",
              "  -0.0064273076,\n",
              "  0.016090982,\n",
              "  0.0067422106,\n",
              "  -0.0050121597,\n",
              "  -0.014735278,\n",
              "  0.012424354,\n",
              "  0.030621652,\n",
              "  0.0075536873,\n",
              "  0.030916726,\n",
              "  0.011890158,\n",
              "  -0.025834924,\n",
              "  0.03748588,\n",
              "  -0.08346887,\n",
              "  -0.031385247,\n",
              "  0.027849615,\n",
              "  -0.042414434,\n",
              "  -0.00894181,\n",
              "  0.060618415,\n",
              "  0.07541968,\n",
              "  -0.012387095,\n",
              "  -0.066086285,\n",
              "  0.04827061,\n",
              "  0.045611568,\n",
              "  0.057779282,\n",
              "  0.011932263,\n",
              "  0.013228877,\n",
              "  -0.001825131,\n",
              "  0.061304033,\n",
              "  0.025735846,\n",
              "  0.021828467,\n",
              "  0.021049991,\n",
              "  0.06719284,\n",
              "  0.008765526,\n",
              "  0.045786526,\n",
              "  -0.0317477,\n",
              "  0.02065141,\n",
              "  -0.009104331,\n",
              "  -0.042121112,\n",
              "  0.012933131,\n",
              "  -0.018211536,\n",
              "  -0.018541787,\n",
              "  -0.060249306,\n",
              "  -0.0052013905,\n",
              "  -0.14632638,\n",
              "  -0.009705608,\n",
              "  -0.036640238,\n",
              "  -0.0063894433,\n",
              "  -0.0025604335,\n",
              "  0.028980626,\n",
              "  0.01568119,\n",
              "  -0.04348183,\n",
              "  0.045813743,\n",
              "  -0.0064925915,\n",
              "  -0.040016316,\n",
              "  0.019366475,\n",
              "  0.02528301,\n",
              "  -0.027627192,\n",
              "  0.05047895,\n",
              "  0.036977977,\n",
              "  -0.029905714,\n",
              "  -0.044019863,\n",
              "  0.0118677635,\n",
              "  -0.018876819,\n",
              "  -0.012316283,\n",
              "  0.012954126,\n",
              "  0.025399135,\n",
              "  0.027765226,\n",
              "  0.005515026,\n",
              "  -0.0063440837,\n",
              "  0.0678735,\n",
              "  0.028103787,\n",
              "  0.05124833,\n",
              "  -0.06289626,\n",
              "  -0.0091720605,\n",
              "  0.0012719007,\n",
              "  0.031095544,\n",
              "  -0.011174427,\n",
              "  0.026543155,\n",
              "  0.02887533,\n",
              "  -0.0027857763,\n",
              "  -0.013543437,\n",
              "  -0.013291456,\n",
              "  0.00032354778,\n",
              "  0.040551275,\n",
              "  -0.00713733,\n",
              "  0.011887834,\n",
              "  0.0006457017,\n",
              "  -0.0034186507,\n",
              "  0.01098586,\n",
              "  0.012614861,\n",
              "  0.0357639,\n",
              "  0.0026134336,\n",
              "  -0.049066715,\n",
              "  0.025942627,\n",
              "  0.033739902,\n",
              "  -0.011950232,\n",
              "  -0.017632708,\n",
              "  0.020742446,\n",
              "  -0.045525897,\n",
              "  -0.024493793,\n",
              "  -0.03467308,\n",
              "  0.025518142,\n",
              "  -0.003994659,\n",
              "  0.012431907,\n",
              "  -0.0024330337,\n",
              "  0.03693533,\n",
              "  -0.039960593,\n",
              "  -0.053846363,\n",
              "  -0.030305913,\n",
              "  -0.016108925,\n",
              "  0.0058787507,\n",
              "  -0.07748664,\n",
              "  0.09489429,\n",
              "  -0.028459303,\n",
              "  0.016096164,\n",
              "  0.022334805,\n",
              "  0.019001676,\n",
              "  -0.017132033,\n",
              "  0.009784741,\n",
              "  0.0411386,\n",
              "  0.037543755,\n",
              "  0.010549018,\n",
              "  0.009500205,\n",
              "  -0.061117932,\n",
              "  0.03281594,\n",
              "  0.024744855,\n",
              "  0.01924117,\n",
              "  -0.037032116,\n",
              "  -0.027741496,\n",
              "  0.0749185,\n",
              "  -0.015016555,\n",
              "  -0.009014491,\n",
              "  -0.0008245026,\n",
              "  0.062026486,\n",
              "  -0.015442887,\n",
              "  0.008683278,\n",
              "  0.051306244,\n",
              "  -0.016263342,\n",
              "  0.038477767,\n",
              "  -0.04849547,\n",
              "  0.008016472,\n",
              "  -0.033911064,\n",
              "  0.009710373,\n",
              "  0.009816229,\n",
              "  0.013334592,\n",
              "  -0.007375553,\n",
              "  0.011389719,\n",
              "  -0.017823296,\n",
              "  0.016177991,\n",
              "  0.020219458,\n",
              "  -0.021342391,\n",
              "  0.04367843,\n",
              "  -0.07579875,\n",
              "  0.00012924596,\n",
              "  0.01335302,\n",
              "  0.030472118,\n",
              "  0.009470989,\n",
              "  0.051821545,\n",
              "  -0.026009057,\n",
              "  -0.029681507,\n",
              "  0.023989465,\n",
              "  0.016444739,\n",
              "  0.019336168,\n",
              "  -0.003593051,\n",
              "  -0.011505347,\n",
              "  -0.039509848,\n",
              "  -0.032273244,\n",
              "  0.03759376,\n",
              "  -0.02245772,\n",
              "  -0.033086374,\n",
              "  0.07537292,\n",
              "  -0.013238603,\n",
              "  0.015572463,\n",
              "  0.04120049,\n",
              "  0.005072585,\n",
              "  -0.00025145148,\n",
              "  9.3769486e-05,\n",
              "  0.009748231,\n",
              "  -0.005433986,\n",
              "  -0.040411945,\n",
              "  -0.00489288,\n",
              "  -0.044275157,\n",
              "  -0.010248191,\n",
              "  0.0054338053,\n",
              "  0.0008364686,\n",
              "  -0.018555515,\n",
              "  0.05552207,\n",
              "  -0.049151745,\n",
              "  -0.0419684,\n",
              "  0.02447831,\n",
              "  -0.019384952,\n",
              "  0.016074568,\n",
              "  -0.041959293,\n",
              "  -0.015979288,\n",
              "  0.06753258,\n",
              "  -0.032814816,\n",
              "  -0.002997757,\n",
              "  0.046755187,\n",
              "  -0.008686372,\n",
              "  0.02248626,\n",
              "  -0.0074039907,\n",
              "  -0.031047061,\n",
              "  -0.0029698,\n",
              "  0.025445128,\n",
              "  0.021256033,\n",
              "  0.001898686,\n",
              "  -0.052674223,\n",
              "  0.01929674,\n",
              "  0.004554737,\n",
              "  -0.03774157,\n",
              "  0.011877261,\n",
              "  0.035086688,\n",
              "  -0.04722955,\n",
              "  -0.057931866,\n",
              "  0.008925549,\n",
              "  0.027149506,\n",
              "  0.026889872,\n",
              "  0.0016159378,\n",
              "  0.0048444984,\n",
              "  0.0005618756,\n",
              "  -0.030419104,\n",
              "  0.05467504,\n",
              "  -0.014060116,\n",
              "  0.012619006,\n",
              "  0.011947526,\n",
              "  0.007317853,\n",
              "  0.053838186,\n",
              "  0.06694349,\n",
              "  -0.023854826,\n",
              "  -0.02209344,\n",
              "  -0.040320124,\n",
              "  -0.050379675,\n",
              "  -0.008739349,\n",
              "  -0.05166991,\n",
              "  -0.028669437,\n",
              "  0.0779809,\n",
              "  -0.016112983,\n",
              "  0.002477409,\n",
              "  0.011120225,\n",
              "  0.037705455,\n",
              "  -0.022606602,\n",
              "  -0.026512751,\n",
              "  0.0075145774,\n",
              "  -0.024778899,\n",
              "  0.007632754,\n",
              "  -0.008147555,\n",
              "  0.027875496,\n",
              "  -0.031255648,\n",
              "  -0.024777789,\n",
              "  0.023553053,\n",
              "  0.015264063,\n",
              "  -0.02400154,\n",
              "  -0.019170443,\n",
              "  0.05169129,\n",
              "  0.022058455,\n",
              "  -0.012917651,\n",
              "  -0.013677392,\n",
              "  -0.06107679,\n",
              "  0.08296265,\n",
              "  0.008282293,\n",
              "  0.017559383,\n",
              "  -0.030741354,\n",
              "  0.040773686,\n",
              "  0.016341483,\n",
              "  0.03355493,\n",
              "  0.0049993363,\n",
              "  -0.022656703,\n",
              "  -0.009107697,\n",
              "  -0.0007255063,\n",
              "  0.0062047057,\n",
              "  -0.0024316965,\n",
              "  0.027707651,\n",
              "  0.013264962,\n",
              "  -0.04203796,\n",
              "  0.06750469,\n",
              "  -0.022321291,\n",
              "  0.062087856,\n",
              "  0.0273184,\n",
              "  0.0028386796,\n",
              "  0.0566346,\n",
              "  0.027528958,\n",
              "  -0.035903126,\n",
              "  -0.0007671516,\n",
              "  0.015142048,\n",
              "  -0.006399644,\n",
              "  -0.051297937,\n",
              "  0.020054173,\n",
              "  0.027084146,\n",
              "  -0.022127705,\n",
              "  -0.0034786544,\n",
              "  -0.012204869,\n",
              "  -0.026689485,\n",
              "  -0.045035627,\n",
              "  -0.022529172,\n",
              "  0.0071038906,\n",
              "  -0.017308358,\n",
              "  -0.011853069,\n",
              "  -2.0408426e-05,\n",
              "  -0.010468661,\n",
              "  0.008122509,\n",
              "  -0.027835866,\n",
              "  0.013644795,\n",
              "  -0.040042564,\n",
              "  -0.034036655,\n",
              "  -0.0086062625,\n",
              "  0.065939434,\n",
              "  -0.028278762,\n",
              "  0.035291165,\n",
              "  0.010113087,\n",
              "  0.049677175,\n",
              "  -0.0059020566,\n",
              "  0.027180927,\n",
              "  -0.019636672,\n",
              "  0.004721508,\n",
              "  0.026030974,\n",
              "  0.026300263,\n",
              "  -0.0048047793,\n",
              "  -0.030193623,\n",
              "  0.01679084,\n",
              "  -0.02900574,\n",
              "  -0.045736205,\n",
              "  -0.027874786,\n",
              "  -0.0023756453,\n",
              "  -0.024239663,\n",
              "  0.017658329,\n",
              "  -0.0033350892,\n",
              "  0.012394304,\n",
              "  0.018693525,\n",
              "  -0.01151512,\n",
              "  0.03005542,\n",
              "  0.030087642,\n",
              "  -0.028678954,\n",
              "  -0.11671204,\n",
              "  -0.0028791938,\n",
              "  -0.007356356,\n",
              "  -0.022924844,\n",
              "  0.037035648,\n",
              "  -0.008008126,\n",
              "  0.037299145,\n",
              "  -0.06379562,\n",
              "  0.042426154,\n",
              "  -0.08072393,\n",
              "  -0.010449093,\n",
              "  -0.030584773,\n",
              "  0.021990212,\n",
              "  0.047973953,\n",
              "  0.024753897,\n",
              "  0.0011809564,\n",
              "  -0.0063404874,\n",
              "  0.015002818,\n",
              "  -0.042391326,\n",
              "  -0.08615401,\n",
              "  -0.0074742013,\n",
              "  0.011827963,\n",
              "  0.009021305,\n",
              "  -0.015771054,\n",
              "  0.00737693,\n",
              "  0.009225591,\n",
              "  0.03280853,\n",
              "  0.03985948,\n",
              "  -0.02431853,\n",
              "  0.0064274045,\n",
              "  -0.00073160476,\n",
              "  0.022450052,\n",
              "  -0.024932038,\n",
              "  0.039277814,\n",
              "  -0.020152079,\n",
              "  -0.0029227773,\n",
              "  -0.023835551,\n",
              "  0.055762578,\n",
              "  0.019660063,\n",
              "  -0.02504836,\n",
              "  0.08693979,\n",
              "  -0.005064358,\n",
              "  -0.0041705845,\n",
              "  0.0064987806,\n",
              "  0.009218088,\n",
              "  -0.016589342,\n",
              "  0.00389345,\n",
              "  -0.009554627,\n",
              "  -0.010032717,\n",
              "  -0.01972707,\n",
              "  0.009409553,\n",
              "  -0.032033492,\n",
              "  -0.03485212,\n",
              "  -0.0061200475,\n",
              "  -0.07181801,\n",
              "  -0.030994903,\n",
              "  -0.03485888,\n",
              "  0.03284576,\n",
              "  -0.00962203,\n",
              "  -0.017611464,\n",
              "  0.0079931775,\n",
              "  0.033278696,\n",
              "  0.032045815,\n",
              "  -0.024923405,\n",
              "  -0.038080726,\n",
              "  0.0550188,\n",
              "  0.028828952,\n",
              "  0.027280524,\n",
              "  0.0489663,\n",
              "  -0.030342283,\n",
              "  0.0019876873,\n",
              "  0.0021054896,\n",
              "  -0.013211499,\n",
              "  0.024841065,\n",
              "  0.03531604,\n",
              "  -0.0057645896,\n",
              "  -0.01093497,\n",
              "  -0.019143384,\n",
              "  -0.021316264,\n",
              "  0.04155887,\n",
              "  0.008049468,\n",
              "  0.05789561,\n",
              "  -0.038308907,\n",
              "  0.011287924,\n",
              "  -0.015262691,\n",
              "  -0.03715904,\n",
              "  -0.026501242,\n",
              "  0.01312857,\n",
              "  0.03531957,\n",
              "  0.009238466,\n",
              "  0.0038388157,\n",
              "  -0.049122646,\n",
              "  0.024371417,\n",
              "  -0.044283282,\n",
              "  -0.05471319,\n",
              "  0.0015639624,\n",
              "  -0.0011887853,\n",
              "  -0.04288307,\n",
              "  0.005135648,\n",
              "  0.027774308,\n",
              "  -0.0040653446,\n",
              "  0.014124749,\n",
              "  0.015166468,\n",
              "  -0.081831776,\n",
              "  0.016452884,\n",
              "  -0.0409587,\n",
              "  0.038180396,\n",
              "  0.016799293,\n",
              "  0.014946657,\n",
              "  0.025060222,\n",
              "  0.039898444,\n",
              "  0.017697187,\n",
              "  0.0042960853,\n",
              "  0.021829914,\n",
              "  0.04924937,\n",
              "  -0.026688363,\n",
              "  -0.022733757,\n",
              "  0.039608963,\n",
              "  0.073605396,\n",
              "  0.029571554,\n",
              "  -0.05154262,\n",
              "  -0.07491381,\n",
              "  0.015214806,\n",
              "  -0.012055175,\n",
              "  0.06564725,\n",
              "  0.0055880323,\n",
              "  0.021129144,\n",
              "  -0.04836406,\n",
              "  0.049045075,\n",
              "  -0.003622305,\n",
              "  -0.029703997,\n",
              "  -0.0069798273,\n",
              "  0.04538029,\n",
              "  -0.022479532,\n",
              "  -0.013689386,\n",
              "  0.0114094205,\n",
              "  -0.05610892,\n",
              "  -0.00964021,\n",
              "  -0.021632876,\n",
              "  -0.008586635,\n",
              "  -0.03254289,\n",
              "  -0.018854735,\n",
              "  -0.0035547563,\n",
              "  -0.018716736,\n",
              "  -0.03708074,\n",
              "  -0.043302394,\n",
              "  0.06884556,\n",
              "  0.047851622,\n",
              "  0.0007315347,\n",
              "  0.033572495,\n",
              "  -0.0015244768,\n",
              "  0.02229747,\n",
              "  -0.028234476,\n",
              "  0.0065856334,\n",
              "  0.035310667,\n",
              "  -0.03143444,\n",
              "  0.06600341,\n",
              "  -0.01360012,\n",
              "  -0.0212523,\n",
              "  -0.092069566,\n",
              "  -0.03280112,\n",
              "  0.013261901,\n",
              "  -0.050003953]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for v in result['embedding']:\n",
        "  print(str(v)[:50], \".....Trimmed.....\", len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30VA2vMGpKG",
        "outputId": "e7b96604-a0cb-4b67-c997-8fec42a55968"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.028602581, 0.048764728, -0.03339466, -0.003734 .....Trimmed..... 768\n",
            "[-0.00966427, 0.030931212, -0.06882039, -0.0235623 .....Trimmed..... 768\n",
            "[0.022403503, 0.022988817, -0.08209265, -0.0204587 .....Trimmed..... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Vector store and retrieval using chroma DB And Langchain"
      ],
      "metadata": {
        "id": "YkmBOZfFZGJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-chroma"
      ],
      "metadata": {
        "id": "zrnLuiohXPQF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Toys come alive and have a blast doing so\",\n",
        "        metadata={\"year\": 1995, \"genre\": \"animated\"}\n",
        "    )\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Y5r71PLaZgq0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "ubkvAE1mb9ff"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "TSMArtLacHiV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_documents([\"what is the meaning of life\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "elo491dodpvR",
        "outputId": "774e51e0-4bb4-49d4-aab6-dbc08368eaa0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[-0.0021001086570322514,\n",
              "  0.024578247219324112,\n",
              "  -0.008393899537622929,\n",
              "  -0.01105791237205267,\n",
              "  -0.045793186873197556,\n",
              "  0.01884854957461357,\n",
              "  -0.009521370753645897,\n",
              "  0.031783029437065125,\n",
              "  -0.02026231773197651,\n",
              "  0.01543511264026165,\n",
              "  0.025989172980189323,\n",
              "  -0.0480426624417305,\n",
              "  0.11126517504453659,\n",
              "  -0.024072963744401932,\n",
              "  -0.002234881278127432,\n",
              "  -0.07736685127019882,\n",
              "  -0.02135997638106346,\n",
              "  0.024497946724295616,\n",
              "  -0.08492584526538849,\n",
              "  -0.003153293626382947,\n",
              "  0.04105377942323685,\n",
              "  -0.01982295513153076,\n",
              "  0.03148310258984566,\n",
              "  7.258095865836367e-05,\n",
              "  0.0073506152257323265,\n",
              "  0.03430982679128647,\n",
              "  -0.009521913714706898,\n",
              "  -0.00879417359828949,\n",
              "  -0.002292716410011053,\n",
              "  0.00229863403365016,\n",
              "  0.07207077741622925,\n",
              "  0.05190161615610123,\n",
              "  0.024998458102345467,\n",
              "  -0.03828039392828941,\n",
              "  0.024370286613702774,\n",
              "  -0.002173005836084485,\n",
              "  -0.008967253379523754,\n",
              "  0.031009098514914513,\n",
              "  0.01921696960926056,\n",
              "  -0.03440364822745323,\n",
              "  -0.07989717274904251,\n",
              "  0.03925313055515289,\n",
              "  -0.03748924657702446,\n",
              "  0.03511207923293114,\n",
              "  -0.03618858382105827,\n",
              "  -0.020349157974123955,\n",
              "  -0.016719715669751167,\n",
              "  0.018734820187091827,\n",
              "  -0.036302391439676285,\n",
              "  0.07634301483631134,\n",
              "  -0.018534423783421516,\n",
              "  0.024205558001995087,\n",
              "  -0.0836988165974617,\n",
              "  0.034091364592313766,\n",
              "  -0.005224080290645361,\n",
              "  -0.0037550958804786205,\n",
              "  -0.020458605140447617,\n",
              "  -0.011805307120084763,\n",
              "  0.03531627357006073,\n",
              "  -0.023848881945014,\n",
              "  -0.008287644013762474,\n",
              "  0.016955817118287086,\n",
              "  -0.026618843898177147,\n",
              "  -0.027436785399913788,\n",
              "  -0.02655254676938057,\n",
              "  0.0279791709035635,\n",
              "  -0.0023748527746647596,\n",
              "  -0.015425479970872402,\n",
              "  -0.03427239507436752,\n",
              "  0.09714806079864502,\n",
              "  0.004402416758239269,\n",
              "  0.06322793662548065,\n",
              "  -0.023507600650191307,\n",
              "  0.03793209418654442,\n",
              "  -0.012381636537611485,\n",
              "  -0.0015081701567396522,\n",
              "  0.002921143313869834,\n",
              "  -0.02715013176202774,\n",
              "  -0.021490363404154778,\n",
              "  0.02531534805893898,\n",
              "  -0.016714448109269142,\n",
              "  0.0038937856443226337,\n",
              "  0.07930458337068558,\n",
              "  0.10394679754972458,\n",
              "  0.010753197595477104,\n",
              "  0.012963350862264633,\n",
              "  -0.009579516015946865,\n",
              "  -0.06338757276535034,\n",
              "  -0.05603306367993355,\n",
              "  -0.019573338329792023,\n",
              "  0.07911071181297302,\n",
              "  0.024380020797252655,\n",
              "  -0.010068674571812153,\n",
              "  -0.014741980470716953,\n",
              "  0.04428735002875328,\n",
              "  -0.005586765240877867,\n",
              "  -0.0779045969247818,\n",
              "  -0.09344912320375443,\n",
              "  0.10226386785507202,\n",
              "  0.023513928055763245,\n",
              "  0.03328722342848778,\n",
              "  0.02869325503706932,\n",
              "  -0.010775940492749214,\n",
              "  -0.07625658065080643,\n",
              "  0.03583197668194771,\n",
              "  0.06882395595312119,\n",
              "  0.018350491300225258,\n",
              "  -0.047807272523641586,\n",
              "  0.007922859862446785,\n",
              "  0.01233696285635233,\n",
              "  -0.010151552967727184,\n",
              "  -0.0655752420425415,\n",
              "  0.015056710690259933,\n",
              "  -0.04918855428695679,\n",
              "  0.0023457042407244444,\n",
              "  -0.009615633636713028,\n",
              "  -0.011753072962164879,\n",
              "  -0.0018401375273242593,\n",
              "  -0.024195218458771706,\n",
              "  0.020922373980283737,\n",
              "  0.005093429237604141,\n",
              "  0.031580232083797455,\n",
              "  -0.016139287501573563,\n",
              "  0.07390215992927551,\n",
              "  0.07135100662708282,\n",
              "  -0.008205675520002842,\n",
              "  -0.007736298255622387,\n",
              "  -0.0321761891245842,\n",
              "  -0.05918572098016739,\n",
              "  -0.030748825520277023,\n",
              "  0.07307632267475128,\n",
              "  -0.0743946060538292,\n",
              "  0.0009415295207872987,\n",
              "  0.031744156032800674,\n",
              "  -0.04840477183461189,\n",
              "  -0.0030430727638304234,\n",
              "  0.07410184293985367,\n",
              "  -0.019327806308865547,\n",
              "  0.03603556379675865,\n",
              "  -0.003947190474718809,\n",
              "  0.007000454235821962,\n",
              "  -0.02938258647918701,\n",
              "  0.010135801509022713,\n",
              "  0.02254338376224041,\n",
              "  0.017137430608272552,\n",
              "  -0.0005136499530635774,\n",
              "  -0.0037708929739892483,\n",
              "  0.033131908625364304,\n",
              "  -0.0339578241109848,\n",
              "  -0.03925807774066925,\n",
              "  -0.03018983267247677,\n",
              "  -0.029830988496541977,\n",
              "  0.07899963855743408,\n",
              "  0.0029771116096526384,\n",
              "  -0.0005828617140650749,\n",
              "  0.008283943869173527,\n",
              "  0.04603642597794533,\n",
              "  -0.008103637024760246,\n",
              "  0.06168920919299126,\n",
              "  -0.01843896694481373,\n",
              "  0.05001497268676758,\n",
              "  -0.06623517721891403,\n",
              "  -0.061434391885995865,\n",
              "  0.013332520611584187,\n",
              "  -0.05391722545027733,\n",
              "  -0.00454809982329607,\n",
              "  0.024311034008860588,\n",
              "  -0.0699373260140419,\n",
              "  -0.01627514138817787,\n",
              "  0.013789667747914791,\n",
              "  -0.021298520267009735,\n",
              "  -0.01111784391105175,\n",
              "  -0.040037062019109726,\n",
              "  -0.1316007524728775,\n",
              "  0.004700211808085442,\n",
              "  -0.005119423381984234,\n",
              "  -0.024638362228870392,\n",
              "  -0.029316755011677742,\n",
              "  -0.007110570557415485,\n",
              "  0.022851286455988884,\n",
              "  0.09296441078186035,\n",
              "  0.031460005789995193,\n",
              "  -0.04734953120350838,\n",
              "  -0.04854057356715202,\n",
              "  0.01183590479195118,\n",
              "  -0.02158752828836441,\n",
              "  0.03384404256939888,\n",
              "  0.05371997132897377,\n",
              "  0.07041455805301666,\n",
              "  0.052988238632678986,\n",
              "  -0.05889756977558136,\n",
              "  0.023990469053387642,\n",
              "  -0.0018668585689738393,\n",
              "  0.041342537850141525,\n",
              "  -0.011855696327984333,\n",
              "  -0.03503137081861496,\n",
              "  0.02576701156795025,\n",
              "  -0.0162330474704504,\n",
              "  -0.031116317957639694,\n",
              "  -0.04667595028877258,\n",
              "  0.020470477640628815,\n",
              "  -0.03545227274298668,\n",
              "  -0.03855983167886734,\n",
              "  0.027318252250552177,\n",
              "  0.002467008773237467,\n",
              "  0.019267700612545013,\n",
              "  -0.02757573500275612,\n",
              "  -0.046890489757061005,\n",
              "  0.004955910611897707,\n",
              "  -0.004185093566775322,\n",
              "  -0.01819457858800888,\n",
              "  0.021345702931284904,\n",
              "  -0.04752033203840256,\n",
              "  -0.03798987716436386,\n",
              "  0.06108999624848366,\n",
              "  0.012955705635249615,\n",
              "  0.08297865837812424,\n",
              "  -0.03464367985725403,\n",
              "  0.09013596922159195,\n",
              "  -0.009217443875968456,\n",
              "  0.00871448777616024,\n",
              "  -0.01797482557594776,\n",
              "  0.03578873351216316,\n",
              "  -0.0009862311417236924,\n",
              "  -0.011685819365084171,\n",
              "  -0.005409257020801306,\n",
              "  -0.035356175154447556,\n",
              "  -0.012481561861932278,\n",
              "  -0.007568522822111845,\n",
              "  -0.032011035829782486,\n",
              "  -0.006368355825543404,\n",
              "  0.013814850710332394,\n",
              "  0.026541246101260185,\n",
              "  0.018840836361050606,\n",
              "  -0.07703699916601181,\n",
              "  0.004809906706213951,\n",
              "  0.014450890012085438,\n",
              "  0.01832185499370098,\n",
              "  -0.03129676356911659,\n",
              "  -0.005439150612801313,\n",
              "  0.03425572067499161,\n",
              "  0.0038402776699513197,\n",
              "  0.002567591844126582,\n",
              "  0.009919557720422745,\n",
              "  0.06890620291233063,\n",
              "  -0.005096724256873131,\n",
              "  0.042695097625255585,\n",
              "  0.046209342777729034,\n",
              "  0.00222092610783875,\n",
              "  -0.045601535588502884,\n",
              "  -0.009898148477077484,\n",
              "  -0.029970509931445122,\n",
              "  0.0002497736131772399,\n",
              "  -0.06741845607757568,\n",
              "  -0.08441481739282608,\n",
              "  -0.049618955701589584,\n",
              "  0.04065466672182083,\n",
              "  -0.00772587675601244,\n",
              "  -0.012087570503354073,\n",
              "  -0.04609094187617302,\n",
              "  0.05481092631816864,\n",
              "  -0.03844333067536354,\n",
              "  -0.04182901605963707,\n",
              "  -0.058440204709768295,\n",
              "  -0.02176065742969513,\n",
              "  -0.0805816650390625,\n",
              "  -0.011875639669597149,\n",
              "  -0.024773232638835907,\n",
              "  0.04303917661309242,\n",
              "  -0.05910882726311684,\n",
              "  0.04249086230993271,\n",
              "  -0.0027752297464758158,\n",
              "  -0.0366586335003376,\n",
              "  -0.02978363446891308,\n",
              "  -0.00965222716331482,\n",
              "  0.018276529386639595,\n",
              "  0.008210377767682076,\n",
              "  0.02074280194938183,\n",
              "  0.02891653962433338,\n",
              "  -0.02843281254172325,\n",
              "  0.0340307280421257,\n",
              "  -0.018351733684539795,\n",
              "  -0.01641963981091976,\n",
              "  0.00042822762043215334,\n",
              "  0.038729552179574966,\n",
              "  -0.05123215541243553,\n",
              "  0.01339879259467125,\n",
              "  0.024075884371995926,\n",
              "  -0.01068846695125103,\n",
              "  0.0044822474010288715,\n",
              "  0.05380541458725929,\n",
              "  0.0439123809337616,\n",
              "  0.015173627994954586,\n",
              "  -0.06996941566467285,\n",
              "  0.02235513925552368,\n",
              "  0.01287674531340599,\n",
              "  0.04823753610253334,\n",
              "  0.019542483612895012,\n",
              "  0.0036388947628438473,\n",
              "  0.007234962657094002,\n",
              "  0.017390500754117966,\n",
              "  0.05549078807234764,\n",
              "  -0.04209176450967789,\n",
              "  0.02623724564909935,\n",
              "  0.019220903515815735,\n",
              "  -0.005293568130582571,\n",
              "  0.0015156950103119016,\n",
              "  -0.00875037256628275,\n",
              "  -0.021511472761631012,\n",
              "  0.04925238713622093,\n",
              "  -0.03548317402601242,\n",
              "  0.028843659907579422,\n",
              "  -0.04201288893818855,\n",
              "  -0.0092273885384202,\n",
              "  -0.05525439232587814,\n",
              "  -0.0351044200360775,\n",
              "  -0.18577840924263,\n",
              "  -0.026250123977661133,\n",
              "  -0.004463740158826113,\n",
              "  -0.015479239635169506,\n",
              "  0.02157728746533394,\n",
              "  0.03980753570795059,\n",
              "  0.031228728592395782,\n",
              "  0.029577180743217468,\n",
              "  0.04112781584262848,\n",
              "  -0.013245228677988052,\n",
              "  0.00398055836558342,\n",
              "  0.024434559047222137,\n",
              "  0.010958547703921795,\n",
              "  0.005258527584373951,\n",
              "  -0.006196449976414442,\n",
              "  -0.02381797693669796,\n",
              "  -0.023050794377923012,\n",
              "  -0.020389828830957413,\n",
              "  0.02853410132229328,\n",
              "  0.039327021688222885,\n",
              "  -0.018750187009572983,\n",
              "  0.030287612229585648,\n",
              "  0.055222395807504654,\n",
              "  0.05683881416916847,\n",
              "  0.030938217416405678,\n",
              "  0.00671775545924902,\n",
              "  0.01616327464580536,\n",
              "  0.0206720270216465,\n",
              "  -0.0268325824290514,\n",
              "  -0.038446374237537384,\n",
              "  -0.022219203412532806,\n",
              "  0.02401457540690899,\n",
              "  0.012667132541537285,\n",
              "  -0.016614506021142006,\n",
              "  0.023029519245028496,\n",
              "  0.06372563540935516,\n",
              "  0.0378899984061718,\n",
              "  -0.05538250133395195,\n",
              "  0.004851881880313158,\n",
              "  -0.05089595541357994,\n",
              "  0.04818428307771683,\n",
              "  0.026127619668841362,\n",
              "  -0.006810776889324188,\n",
              "  0.005693228915333748,\n",
              "  -0.020522788166999817,\n",
              "  -0.046606115996837616,\n",
              "  -0.010192185640335083,\n",
              "  -0.017076963558793068,\n",
              "  0.014926510863006115,\n",
              "  -0.015744997188448906,\n",
              "  0.01050590444356203,\n",
              "  0.04799012094736099,\n",
              "  0.006565927993506193,\n",
              "  -0.033457446843385696,\n",
              "  0.026551606133580208,\n",
              "  6.5853979322128e-05,\n",
              "  -0.01847214810550213,\n",
              "  -0.005803197622299194,\n",
              "  0.022576142102479935,\n",
              "  -0.0002866129216272384,\n",
              "  -0.03929746150970459,\n",
              "  0.029428832232952118,\n",
              "  0.015717800706624985,\n",
              "  0.0011994079686701298,\n",
              "  -0.02275731973350048,\n",
              "  -0.02806355617940426,\n",
              "  -0.01741715893149376,\n",
              "  0.007153322920203209,\n",
              "  -0.021332722157239914,\n",
              "  0.061141449958086014,\n",
              "  -0.037416983395814896,\n",
              "  -0.01725069247186184,\n",
              "  0.008084981702268124,\n",
              "  0.013706497848033905,\n",
              "  -0.054718948900699615,\n",
              "  0.07367920875549316,\n",
              "  0.03479324281215668,\n",
              "  0.010952173732221127,\n",
              "  -0.0025748885236680508,\n",
              "  0.04151114821434021,\n",
              "  -0.02169860526919365,\n",
              "  0.021795688197016716,\n",
              "  -0.019700203090906143,\n",
              "  0.018644390627741814,\n",
              "  0.0004777199646923691,\n",
              "  -0.028859803453087807,\n",
              "  0.10077577084302902,\n",
              "  -0.0777270495891571,\n",
              "  -0.02849954552948475,\n",
              "  0.01351495087146759,\n",
              "  0.06898873299360275,\n",
              "  -0.023837940767407417,\n",
              "  -0.007374140899628401,\n",
              "  -0.02012987807393074,\n",
              "  -0.032370615750551224,\n",
              "  -0.029286302626132965,\n",
              "  0.013427403755486012,\n",
              "  0.0042206100188195705,\n",
              "  -0.0353049710392952,\n",
              "  -0.01698712445795536,\n",
              "  0.004958756268024445,\n",
              "  -0.010973626747727394,\n",
              "  0.0011260202154517174,\n",
              "  0.030365219339728355,\n",
              "  0.023669235408306122,\n",
              "  -0.005756856873631477,\n",
              "  0.019846193492412567,\n",
              "  -0.024335896596312523,\n",
              "  0.019567111507058144,\n",
              "  -0.0397215373814106,\n",
              "  0.006366925314068794,\n",
              "  0.03797018527984619,\n",
              "  -0.034800246357917786,\n",
              "  0.048018503934144974,\n",
              "  0.034068990498781204,\n",
              "  0.055854521691799164,\n",
              "  -0.02411814220249653,\n",
              "  0.06465160846710205,\n",
              "  0.04823680594563484,\n",
              "  0.056662775576114655,\n",
              "  -0.015358028002083302,\n",
              "  0.0069477250799536705,\n",
              "  -0.044651199132204056,\n",
              "  0.012233735993504524,\n",
              "  -0.011582845821976662,\n",
              "  -0.027063431218266487,\n",
              "  0.04558253288269043,\n",
              "  0.025375358760356903,\n",
              "  0.0035806577652692795,\n",
              "  0.020087797194719315,\n",
              "  0.051841024309396744,\n",
              "  0.04592736065387726,\n",
              "  -0.04818261042237282,\n",
              "  -0.01558680273592472,\n",
              "  -0.008879659697413445,\n",
              "  -0.005329814739525318,\n",
              "  -0.021354179829359055,\n",
              "  -0.007997828535735607,\n",
              "  -0.02512308768928051,\n",
              "  -0.032609082758426666,\n",
              "  -0.025004053488373756,\n",
              "  0.024199729785323143,\n",
              "  -0.039550889283418655,\n",
              "  0.019174806773662567,\n",
              "  -0.0032700912561267614,\n",
              "  -0.03607065603137016,\n",
              "  0.07493874430656433,\n",
              "  0.031270816922187805,\n",
              "  -0.0004373409319669008,\n",
              "  -0.003487837966531515,\n",
              "  0.01672215200960636,\n",
              "  0.0030070231296122074,\n",
              "  -0.0641767680644989,\n",
              "  0.07201620191335678,\n",
              "  0.009000726975500584,\n",
              "  -0.0035484402906149626,\n",
              "  0.03126423805952072,\n",
              "  0.018692495301365852,\n",
              "  -0.02607261762022972,\n",
              "  -0.015409666113555431,\n",
              "  0.020494433119893074,\n",
              "  -0.032626066356897354,\n",
              "  -0.03726745769381523,\n",
              "  0.013570715673267841,\n",
              "  -0.023846862837672234,\n",
              "  0.02459905855357647,\n",
              "  -0.01722833327949047,\n",
              "  0.022378504276275635,\n",
              "  0.028508836403489113,\n",
              "  -0.0030389390885829926,\n",
              "  -0.03467942029237747,\n",
              "  0.008557135239243507,\n",
              "  0.011425627395510674,\n",
              "  0.009261258877813816,\n",
              "  -0.03445591405034065,\n",
              "  0.02089627832174301,\n",
              "  -0.007963983342051506,\n",
              "  -0.043588150292634964,\n",
              "  -0.002631932031363249,\n",
              "  -0.015719516202807426,\n",
              "  0.03387996181845665,\n",
              "  -0.03624260425567627,\n",
              "  0.04114284738898277,\n",
              "  0.013004153966903687,\n",
              "  0.0919194296002388,\n",
              "  0.019373657181859016,\n",
              "  -0.03041001409292221,\n",
              "  -0.028447119519114494,\n",
              "  -0.031530119478702545,\n",
              "  0.03799761086702347,\n",
              "  -0.042593009769916534,\n",
              "  -0.04398101568222046,\n",
              "  0.05623231083154678,\n",
              "  0.011393578723073006,\n",
              "  0.027824409306049347,\n",
              "  0.002171471482142806,\n",
              "  0.017592450603842735,\n",
              "  0.002833722159266472,\n",
              "  -0.007496459875255823,\n",
              "  0.028048161417245865,\n",
              "  -0.020140988752245903,\n",
              "  0.04216570407152176,\n",
              "  -0.04726599529385567,\n",
              "  0.06918628513813019,\n",
              "  -0.01567876897752285,\n",
              "  -0.015375354327261448,\n",
              "  0.02917437255382538,\n",
              "  0.007726583629846573,\n",
              "  0.024313751608133316,\n",
              "  -0.018503842875361443,\n",
              "  0.022665660828351974,\n",
              "  0.012247186154127121,\n",
              "  0.0021669482812285423,\n",
              "  -0.061887819319963455,\n",
              "  -0.021386420354247093,\n",
              "  0.0614926777780056,\n",
              "  0.029654255136847496,\n",
              "  0.020173272117972374,\n",
              "  0.03188696131110191,\n",
              "  0.0435166209936142,\n",
              "  0.043305084109306335,\n",
              "  0.021398279815912247,\n",
              "  0.001743230503052473,\n",
              "  0.04513312503695488,\n",
              "  0.019962342455983162,\n",
              "  -0.004774779547005892,\n",
              "  0.006729308050125837,\n",
              "  0.04055510088801384,\n",
              "  0.04827793687582016,\n",
              "  -0.030024923384189606,\n",
              "  0.005239007528871298,\n",
              "  0.05794387310743332,\n",
              "  0.014972873963415623,\n",
              "  0.09376123547554016,\n",
              "  0.025383124127984047,\n",
              "  -0.025709712877869606,\n",
              "  0.009822436608374119,\n",
              "  0.003519028425216675,\n",
              "  -0.02701270766556263,\n",
              "  -0.03219358250498772,\n",
              "  0.012269143015146255,\n",
              "  -0.027874421328306198,\n",
              "  -0.014611356891691685,\n",
              "  -0.01689228042960167,\n",
              "  -0.014738899655640125,\n",
              "  -0.010097803547978401,\n",
              "  0.03113071247935295,\n",
              "  0.008639448322355747,\n",
              "  -0.03515008091926575,\n",
              "  0.02081332914531231,\n",
              "  -0.0009230590658262372,\n",
              "  0.004510245751589537,\n",
              "  -0.0325690433382988,\n",
              "  -0.008146990090608597,\n",
              "  -0.006241151597350836,\n",
              "  -0.008994669653475285,\n",
              "  -0.007799308747053146,\n",
              "  -0.024557365104556084,\n",
              "  -0.005988838616758585,\n",
              "  0.016442280262708664,\n",
              "  -0.03716856241226196,\n",
              "  0.03082956187427044,\n",
              "  -0.01694566011428833,\n",
              "  -0.050679754465818405,\n",
              "  0.008149473927915096,\n",
              "  0.005876673385500908,\n",
              "  0.029534580186009407,\n",
              "  0.030074378475546837,\n",
              "  0.015510226599872112,\n",
              "  0.012891261838376522,\n",
              "  0.028838355094194412,\n",
              "  0.01147290226072073,\n",
              "  -0.024273671209812164,\n",
              "  0.013896885327994823,\n",
              "  -0.008145274594426155,\n",
              "  0.07433431595563889,\n",
              "  0.035601306706666946,\n",
              "  -0.05735509842634201,\n",
              "  0.011934340000152588,\n",
              "  -0.02311652898788452,\n",
              "  -0.023735759779810905,\n",
              "  0.023144695907831192,\n",
              "  0.02003556489944458,\n",
              "  0.03073645383119583,\n",
              "  -0.03825828805565834,\n",
              "  -0.0003361768031027168,\n",
              "  0.05295306816697121,\n",
              "  0.0013589058071374893,\n",
              "  -0.00761063490062952,\n",
              "  -0.05337309092283249,\n",
              "  -0.010527321137487888,\n",
              "  -0.04417455568909645,\n",
              "  -0.0033810087479650974,\n",
              "  -0.057251717895269394,\n",
              "  0.01433566678315401,\n",
              "  0.033734772354364395,\n",
              "  -0.041069164872169495,\n",
              "  0.026499448344111443,\n",
              "  -0.07948621362447739,\n",
              "  0.0020669882651418447,\n",
              "  -0.046866316348314285,\n",
              "  -0.00936922151595354,\n",
              "  0.02413821965456009,\n",
              "  -0.00901926588267088,\n",
              "  -0.03847136348485947,\n",
              "  0.013227215968072414,\n",
              "  0.04587654396891594,\n",
              "  -0.004151292610913515,\n",
              "  -0.09651361405849457,\n",
              "  0.008765996433794498,\n",
              "  -0.02597690187394619,\n",
              "  -0.02662372961640358,\n",
              "  0.012139493599534035,\n",
              "  0.018518630415201187,\n",
              "  -0.045121584087610245,\n",
              "  0.0219131950289011,\n",
              "  0.028842244297266006,\n",
              "  -0.016463717445731163,\n",
              "  -0.021820994094014168,\n",
              "  0.0038874964229762554,\n",
              "  0.004081712570041418,\n",
              "  0.0004142767866142094,\n",
              "  0.011827563866972923,\n",
              "  0.013436521403491497,\n",
              "  -0.011897175572812557,\n",
              "  -0.020754938945174217,\n",
              "  0.03646053001284599,\n",
              "  0.031618960201740265,\n",
              "  -0.03780585899949074,\n",
              "  0.08402992784976959,\n",
              "  -0.009557115845382214,\n",
              "  -0.00020288070663809776,\n",
              "  0.0488475076854229,\n",
              "  0.020344140008091927,\n",
              "  -0.0016446965746581554,\n",
              "  -0.005694748368114233,\n",
              "  0.012205634266138077,\n",
              "  -0.0035787250380963087,\n",
              "  0.007409153506159782,\n",
              "  0.05816259607672691,\n",
              "  -0.08275450021028519,\n",
              "  -0.031661901623010635,\n",
              "  0.009979547001421452,\n",
              "  -0.005633129272609949,\n",
              "  0.050625335425138474,\n",
              "  -0.028502486646175385,\n",
              "  0.011186101473867893,\n",
              "  -0.005562064703553915,\n",
              "  0.0021155579015612602,\n",
              "  0.015157444402575493,\n",
              "  0.043350331485271454,\n",
              "  0.04294416680932045,\n",
              "  0.01233272347599268,\n",
              "  -0.021030034869909286,\n",
              "  -0.01700160838663578,\n",
              "  0.040744490921497345,\n",
              "  0.015602173283696175,\n",
              "  -0.001421840162947774,\n",
              "  -0.03667425736784935,\n",
              "  0.04080240800976753,\n",
              "  0.03472309187054634,\n",
              "  0.014248295687139034,\n",
              "  -0.012042054906487465,\n",
              "  0.015399635769426823,\n",
              "  0.006707893684506416,\n",
              "  -0.028715714812278748,\n",
              "  -0.004816065542399883,\n",
              "  -0.029124503955245018,\n",
              "  -0.006463703233748674,\n",
              "  0.030876455828547478,\n",
              "  0.06598057597875595,\n",
              "  -0.0026419758796691895,\n",
              "  -0.06969361007213593,\n",
              "  0.02811363898217678,\n",
              "  -0.030177094042301178,\n",
              "  -0.06357735395431519,\n",
              "  0.0009353721980005503,\n",
              "  -0.02498888596892357,\n",
              "  0.01593790575861931,\n",
              "  0.04305879771709442,\n",
              "  -0.029480230063199997,\n",
              "  0.044608548283576965,\n",
              "  -0.033182013779878616,\n",
              "  -0.011442698538303375,\n",
              "  -0.024882247671484947,\n",
              "  -0.03169665485620499,\n",
              "  -0.06600810587406158,\n",
              "  -0.008815822191536427,\n",
              "  0.02916615456342697,\n",
              "  0.009446784853935242,\n",
              "  0.016232846304774284,\n",
              "  -0.007797964848577976,\n",
              "  -0.06262833625078201,\n",
              "  0.022856932133436203,\n",
              "  -0.02166702225804329,\n",
              "  0.03633978217840195,\n",
              "  0.03939235210418701,\n",
              "  0.019181212410330772,\n",
              "  -0.028768319636583328,\n",
              "  0.04337221756577492,\n",
              "  0.01357991248369217,\n",
              "  -0.014414450153708458,\n",
              "  0.013103206641972065,\n",
              "  -0.01128770038485527,\n",
              "  0.029482487589120865,\n",
              "  -0.03833231329917908,\n",
              "  0.006758828181773424,\n",
              "  0.047115303575992584,\n",
              "  0.045784007757902145,\n",
              "  -0.01191638596355915,\n",
              "  -0.09143958985805511,\n",
              "  -0.02178141102194786,\n",
              "  -0.03950415179133415,\n",
              "  0.05301749333739281,\n",
              "  0.10246384888887405,\n",
              "  0.017646532505750656,\n",
              "  -0.010747016407549381,\n",
              "  0.02610008604824543,\n",
              "  -0.020357977598905563,\n",
              "  -0.008415971882641315,\n",
              "  -0.022311214357614517,\n",
              "  -2.8975420718779787e-05,\n",
              "  -0.013076132163405418,\n",
              "  -0.034224092960357666,\n",
              "  0.04844071343541145,\n",
              "  -0.060862746089696884,\n",
              "  -0.040195658802986145,\n",
              "  -0.03785357251763344,\n",
              "  -0.02431764081120491,\n",
              "  -0.023367995396256447,\n",
              "  -0.048107657581567764,\n",
              "  -0.021131958812475204,\n",
              "  -0.03818129375576973,\n",
              "  -0.01857062615454197,\n",
              "  -0.07606416940689087,\n",
              "  -0.03001049906015396,\n",
              "  -0.000329487316776067,\n",
              "  0.06659587472677231,\n",
              "  0.03600732982158661,\n",
              "  -0.020328795537352562,\n",
              "  -0.04535951837897301,\n",
              "  -0.0053191944025456905,\n",
              "  0.058033011853694916,\n",
              "  0.044742826372385025,\n",
              "  -0.04525609314441681,\n",
              "  0.05745508149266243,\n",
              "  -0.002499660477042198,\n",
              "  0.0009624710073694587,\n",
              "  -0.09057021886110306,\n",
              "  0.006246564909815788,\n",
              "  0.014501691795885563,\n",
              "  -0.037422455847263336]]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings.embed_documents(\"what is the meaning of life\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8BQrQBZd_wQ",
        "outputId": "c5b1d057-b861-4a53-823e-c19a8fff1c05"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E3miwsRC7ifW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "cpPnIiuMpSrX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents, embedding= embeddings)"
      ],
      "metadata": {
        "id": "ceAO6OCaeK6d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ujECdeOvfp2M",
        "outputId": "6511be9c-0f21-4a98-ba9c-f6a4def12718"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zP2TzVm1crN",
        "outputId": "24dbef9d-e2cc-4b29-a06b-9798c56abdd1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7905841d80a0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Store Similarity_Search"
      ],
      "metadata": {
        "id": "fsMTD4hYZ-Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"tell about Leo dicaprio\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf8-N1f41gWI",
        "outputId": "ed5c1b64-fdee-4a9f-81c4-3033bde14859"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='4142142e-59a4-45a0-a233-6df1ac9f7b8a', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
              " Document(id='4f6782be-d341-4543-a445-5a0ed8fc025a', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
              " Document(id='e8f3362b-e488-4380-9c96-47047ad8b977', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              " Document(id='35378c4d-12c2-48df-a7c9-25476fff9006', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vector store by asimilarity search"
      ],
      "metadata": {
        "id": "ZaiPBKDzaDe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.asimilarity_search('tell about leo dicaprio')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQNMh3rhW-E4",
        "outputId": "100d2db9-dd0a-48d6-f8b3-7b66298792fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coroutine object VectorStore.asimilarity_search at 0x7905ba7ae260>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vector store similarity_search with score"
      ],
      "metadata": {
        "id": "KYnHIl1ZaJ0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search_with_score('tell about leo dicaprio')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2YjV6GsXGJb",
        "outputId": "782f9c5b-0504-4532-9544-1d7d328ddc9d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='4142142e-59a4-45a0-a233-6df1ac9f7b8a', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
              "  0.8005845546722412),\n",
              " (Document(id='e8f3362b-e488-4380-9c96-47047ad8b977', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              "  1.1623592376708984),\n",
              " (Document(id='96325c88-0cfa-4a8f-b74b-e766d9fbe8aa', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
              "  1.2405102252960205),\n",
              " (Document(id='3e6e83ce-9e89-4dea-b4e3-95348b47b587', metadata={'genre': 'animated', 'year': 1995}, page_content='Toys come alive and have a blast doing so'),\n",
              "  1.2884230613708496)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Store Similarity search by Vector"
      ],
      "metadata": {
        "id": "aqfIph3MZeul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embeddings.embed_query(\"tell about leo dicaprio\")\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoPlFGwnXYii",
        "outputId": "871af2c3-01f5-499a-9b04-6b07aab290ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='4142142e-59a4-45a0-a233-6df1ac9f7b8a', metadata={'director': 'Christopher Nolan', 'rating': 8.2, 'year': 2010}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
              " Document(id='e8f3362b-e488-4380-9c96-47047ad8b977', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              " Document(id='96325c88-0cfa-4a8f-b74b-e766d9fbe8aa', metadata={'director': 'Satoshi Kon', 'rating': 8.6, 'year': 2006}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
              " Document(id='3e6e83ce-9e89-4dea-b4e3-95348b47b587', metadata={'genre': 'animated', 'year': 1995}, page_content='Toys come alive and have a blast doing so')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers"
      ],
      "metadata": {
        "id": "2q9rR-w7bcTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)"
      ],
      "metadata": {
        "id": "Qx7nTAI2ZWcD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "f48qPcSc7fXn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "VR6yQjeu9Rjl"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(\"tell me the allama iqbal born date\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pw7dJMn-Mox",
        "outputId": "8cc98d6d-4c4a-4a46-a9e6-839ac0d1e40c"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allama Iqbal was born on **November 9, 1877**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "\n",
        "Answer this question uses the provided context only.\n",
        "{question}\n",
        "context:{context}\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "71WVmn1feWFC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([('human',message)])"
      ],
      "metadata": {
        "id": "KRhvCaTDgrVB"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG System"
      ],
      "metadata": {
        "id": "fMsQDXfmjoBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {'context': retriever, 'question': RunnablePassthrough()} | prompt | llm"
      ],
      "metadata": {
        "id": "w8nKMYsmiuud"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell me about allama iqbal\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIn8Vf6dkJEg",
        "outputId": "2e35eae7-6cd2-4ebd-ffad-e8be7884f3ef"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided text does not contain any information about Allama Iqbal.  Therefore, I cannot answer your question using only the given context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now use google gemini embedding model for retriever"
      ],
      "metadata": {
        "id": "kDy_t7f7F0eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection With Embedding"
      ],
      "metadata": {
        "id": "R9L-S5XDF_d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU facenet-pytorch"
      ],
      "metadata": {
        "id": "CmrsPT-Aki-_"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGuvTWbwN2w3",
        "outputId": "4d94dcac-0ae8-45c4-eee8-814e3b07a001"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3.4/4.5 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V4LdUKoDgVDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# libraries of image processing and create embaddings"
      ],
      "metadata": {
        "id": "DlcedlWcgm7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "QKu1Hj5dGkoQ"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08059da1c93b42989bbe6ae1258fb0ca",
            "d6a1ef40cb4c434da12395d7273d7867",
            "037e2ad20a2d446fb51705c4dac21122",
            "9a527c353ab94827aa6e3dbfa5446e3b",
            "4b497909a61f4a429801f76f9073e8b3",
            "8678bcb539c64d8683aac141a097b48b",
            "001a34ad7eed4e4283b925341d498c48",
            "c82f32ab79a24b7d89e571813cb3cc85",
            "eb8493af01234449824c54ec2fa5cc36",
            "811ceb2908f04b4bb52f0256fa56a3ec",
            "61fffcb866204593b9d0ad496aec571b"
          ]
        },
        "collapsed": true,
        "id": "fs0chav3NJ5E",
        "outputId": "05b6432e-8466-4b8f-fb85-6c86b2761d01"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08059da1c93b42989bbe6ae1258fb0ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function to preprocess the image\n",
        "# function to create the embeddings"
      ],
      "metadata": {
        "id": "scbCD4T_gL4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing function to transform the image into tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "# function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "      input_tensor = preprocess_image(image_path)\n",
        "      with torch.no_grad():\n",
        "        embedding = model(input_tensor) # embedding important line\n",
        "      return embedding.squeeze().tolist()\n",
        "    except Exception as e:\n",
        "      print(\"Error\",e)\n",
        "      return None"
      ],
      "metadata": {
        "id": "9CLYedcrOkrW"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To create image directory"
      ],
      "metadata": {
        "id": "HVa89l5OgAot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "tA9sSl-jS-_I"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating the embeddings of one image"
      ],
      "metadata": {
        "id": "UhaUEiekgEIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/images/Ahmad-1.jpg\"\n",
        "A1 = create_image_embedding(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA226sBUTGwe",
        "outputId": "00b3307f-1b27-47aa-a519-2e104ec0448f"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# to see the embeddings and dimension"
      ],
      "metadata": {
        "id": "1iERMOGnf1JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(A1))\n",
        "print(\"image embedding\",A1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcAcwV_8Vt13",
        "outputId": "bf084eaa-f947-43a0-8176-89f7b24c06ef"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "image embedding [-0.02082901820540428, 0.018024098128080368, -0.059124384075403214, 0.08827550709247589, 0.05649910494685173, 0.061136651784181595, -0.02989034168422222, 0.0626065731048584, -0.02571144513785839, 0.02431570179760456, -0.0441824235022068, 0.053858574479818344, -0.045460257679224014, 0.000305745197692886, -0.042346686124801636, -0.012164090760052204, 0.03745798394083977, 0.03639063984155655, 0.03492416441440582, -0.11006766557693481, -0.04977138340473175, 0.06485258042812347, 0.06182479113340378, 0.029191970825195312, 0.024867184460163116, 0.06290283799171448, 0.0595218688249588, -0.01829824224114418, 0.03293030709028244, 0.045580316334962845, -0.08487293869256973, -0.03818577155470848, 0.022902002558112144, -0.035334281623363495, -0.01245000772178173, 0.058870911598205566, -0.017181530594825745, -0.01417376846075058, -0.06113668903708458, 0.03869987279176712, -0.029799140989780426, 0.03221594914793968, 0.03236699104309082, -0.009717280976474285, -0.002754571847617626, 0.015274759382009506, -0.019986005499958992, 0.08974486589431763, -0.09264031052589417, 0.019839737564325333, 0.025799252092838287, 0.04302758350968361, 0.056652624160051346, -0.014560959301888943, -0.07991566509008408, 0.04799839109182358, -0.015114450827240944, 0.10420659929513931, 0.01989087276160717, -0.06760561466217041, 0.042396076023578644, 0.014268829487264156, -0.006132759619504213, -0.0752766951918602, -0.05309204012155533, 0.037779904901981354, -0.032695554196834564, 0.034337542951107025, 0.03471336513757706, 0.06268875300884247, 0.027300067245960236, 0.044482871890068054, 0.006766737438738346, 0.015918100252747536, 0.029357563704252243, -0.0017868822906166315, -0.06298646330833435, 0.008131397888064384, -0.025464890524744987, 0.036929015070199966, 0.059804901480674744, 0.012695405632257462, 0.017640365287661552, 0.0032886259723454714, -0.018199574202299118, 0.05060557276010513, 0.015795642510056496, 0.025708243250846863, -0.026531152427196503, -0.021832797676324844, 0.003999423235654831, -0.023280808702111244, 0.047492239624261856, -0.03337695449590683, 0.08008459210395813, -0.0072167967446148396, 0.022391583770513535, 0.0040476080030202866, -0.05658759921789169, 0.044347092509269714, 0.0480966717004776, -0.038188472390174866, -0.00834810733795166, 0.0055740573443472385, -0.001567619270645082, 0.010555214248597622, 0.026508811861276627, -0.024773243814706802, 0.03801858425140381, -0.09039835631847382, 0.057721443474292755, 0.002990146167576313, -0.05041578784584999, -0.09420217573642731, 0.03908781334757805, -0.05311848968267441, 0.054540473967790604, -0.006276147440075874, -0.026370692998170853, 0.006939568091183901, -0.018385829403996468, 0.026954974979162216, -0.03117605485022068, -0.04583479464054108, -0.04263163357973099, -0.09731122851371765, 0.0012976910220459104, 0.0789952203631401, 0.005686632823199034, 0.0001880236086435616, -0.021127115935087204, -0.03104924038052559, 0.06298956274986267, -0.05639464408159256, -0.1193152368068695, -0.0018016357207670808, 0.011930027976632118, 0.025557730346918106, 0.06393144279718399, 0.12400248646736145, 0.007385602220892906, 0.026355931535363197, 0.024700680747628212, 0.041635941714048386, 0.03866150602698326, -0.02376154623925686, 0.022807249799370766, -0.018206078559160233, 0.008427515625953674, -0.018771667033433914, 0.03788470849394798, -0.0354483425617218, -0.053976502269506454, 0.043729521334171295, 0.03535343334078789, -0.029973343014717102, 0.0027801007963716984, 0.05779547616839409, 0.02878793142735958, -0.03632458299398422, 0.07522376626729965, 0.046934548765420914, -0.033373404294252396, 0.07488229125738144, 0.07362036406993866, 0.05152348056435585, -0.04240848869085312, -0.04985182732343674, -0.07359234243631363, 0.0681825578212738, -0.007737921550869942, -0.03237796202301979, -0.01920946314930916, -0.0012919568689540029, 0.055352382361888885, 0.030566522851586342, 0.028965946286916733, -0.03270307183265686, -0.06711137294769287, 0.02226576954126358, -0.06497667729854584, -0.05733676627278328, -0.049654413014650345, 0.051788996905088425, 0.029917055740952492, 0.004848553333431482, 0.022730467841029167, 0.026417214423418045, 0.04117639362812042, 0.05844233185052872, 0.05753841623663902, 0.018606754019856453, 0.058327365666627884, -0.07549267262220383, 0.05589287728071213, -0.033075038343667984, 0.004316059406846762, 0.019410958513617516, -0.039339013397693634, 0.06948532164096832, 0.012307805009186268, 0.0029499423690140247, -0.02282140590250492, -0.049701839685440063, 0.035374026745557785, 0.040489859879016876, 0.028479591012001038, -0.046704068779945374, -0.02833426557481289, -0.019094694405794144, -0.010525638237595558, -0.056886717677116394, 0.025562280789017677, 0.015894528478384018, 0.0007585469866171479, 0.03080134093761444, -0.045171428471803665, 0.030537297949194908, -0.047288812696933746, 0.009849206544458866, -0.08972837030887604, -0.1085229441523552, -0.02362695150077343, -0.04983644559979439, -0.007031221408396959, 0.002069015521556139, -0.05697501823306084, -0.015397665090858936, 0.023567916825413704, -0.00855568889528513, 0.04712963476777077, 0.07101622968912125, -0.028777113184332848, -0.06273262947797775, -0.00876684207469225, -0.013903804123401642, 0.05860312283039093, -0.04914969205856323, -0.0364980474114418, -0.008065452799201012, -0.029217036440968513, -0.046871285885572433, 0.0012041678419336677, 0.027335651218891144, 0.08308864384889603, 0.09426306188106537, 0.005218779668211937, 0.023588713258504868, -0.0027683163061738014, 0.026477767154574394, 0.013852962292730808, 0.04227238520979881, 0.006553203333169222, 0.03690165653824806, 0.025356559082865715, -0.005006727296859026, -0.014171842485666275, 0.03425315022468567, 0.04228043183684349, 0.060041386634111404, 0.009235220029950142, 0.003915962763130665, 0.033235643059015274, -0.008384556509554386, -0.08321273326873779, -0.02663848176598549, 0.04736091196537018, -0.017570436000823975, -0.04028590768575668, 0.03155555576086044, -0.020460041239857674, 0.01875966042280197, -0.030490817502141, 0.010464177466928959, 0.004746139049530029, -0.049742721021175385, 0.00700142327696085, 0.037154652178287506, 0.007415796164423227, -0.03873569145798683, 0.07248309999704361, -0.01786976307630539, -0.0382235050201416, -0.10070019960403442, -0.060159116983413696, -0.03933452442288399, 0.004863304551690817, 0.025282518938183784, -0.04093893989920616, -0.06532808393239975, 0.005139731336385012, -0.09182696044445038, 0.012890193611383438, -0.011077683418989182, -0.04383686184883118, -0.07572806626558304, -0.03728363662958145, 0.06796430051326752, 0.03592362254858017, 0.03541187569499016, 0.0866343304514885, -0.015833862125873566, 0.049007076770067215, 0.04611004516482353, 0.04286889359354973, -0.0547969751060009, -0.020499225705862045, -0.025717053562402725, -0.013110091909766197, 0.023466169834136963, 0.015576928853988647, 0.04308159276843071, -0.010112129151821136, 0.03222615271806717, 0.08047907799482346, 0.0440666601061821, -0.003392180660739541, 0.032579608261585236, -0.009602384641766548, -0.017200885340571404, 0.10689374804496765, 0.02624577097594738, -0.04675360769033432, 0.02834389917552471, -0.09279840439558029, 0.08907856792211533, 0.004001258406788111, -0.01631881855428219, 0.056945107877254486, 0.01787547953426838, 0.036132290959358215, -0.010436111129820347, -0.012370740063488483, 0.08177398145198822, -0.003696151776239276, 0.008057764731347561, -0.01282211858779192, 0.018512731418013573, 0.0167223010212183, -0.038786087185144424, 0.052227701991796494, 0.06875031441450119, 0.0601743683218956, -0.006110412534326315, -0.03030429780483246, -0.036407001316547394, -0.043768446892499924, 0.04696910083293915, 0.07362552732229233, -0.057763490825891495, -0.041961293667554855, 0.015261842869222164, -0.05505993217229843, -0.03730834275484085, -0.06775492429733276, 0.007832401432096958, 0.07961459457874298, 0.01152409054338932, -0.026559660211205482, -0.005676702596247196, -0.012717106379568577, 0.024617383256554604, -0.02672784961760044, 0.016724485903978348, -0.02119545079767704, 0.017567243427038193, 0.0763772651553154, -0.011759406886994839, 0.014126154594123363, -0.03308006003499031, -0.05985471233725548, 0.014284336939454079, 0.01509364414960146, 0.008233205415308475, 0.047666389495134354, 0.06298819184303284, -0.07415442913770676, 0.012462865561246872, -0.030645139515399933, -0.020443923771381378, -0.004587418399751186, -0.0014776404714211822, -0.043297745287418365, 0.0641164630651474, 0.08031324297189713, -0.01915832981467247, -0.011814920231699944, -0.04563576728105545, -0.0034418466966599226, -0.0088852783665061, 0.014567121863365173, 0.05833936482667923, 0.019918829202651978, -0.05836695432662964, -0.07419616729021072, -0.013732559978961945, 0.08363673835992813, 0.034508924931287766, 0.039769504219293594, 0.049265239387750626, -0.045780934393405914, 0.024365518242120743, -0.030655542388558388, 0.026541709899902344, -0.01915428414940834, 0.0011997814290225506, -0.02597665600478649, -0.035223864018917084, 0.051019325852394104, 0.017033537849783897, 0.027926845476031303, -0.03350522741675377, -0.003636457957327366, 0.025311263278126717, -0.015608079731464386, -0.01890118233859539, 0.02483980730175972, 0.029274530708789825, -0.01930745504796505, -0.034952424466609955, 0.06279559433460236, 0.0008195428526960313, 0.04534466937184334, -0.013002376072108746, -0.05925433337688446, -0.012755555100739002, 0.05610905587673187, 0.016343984752893448, 0.020785653963685036, -0.04874137416481972, 0.006489581894129515, 0.03142228722572327, -0.06193559244275093, -0.021482102572917938, -0.05678308382630348, -0.03217880800366402, -0.01908935233950615, -0.00447366526350379, 0.02719585970044136, -0.018551809713244438, -0.04970471188426018, 0.015444468706846237, -0.036810360848903656, 0.06515118479728699, -0.041205137968063354, 0.02296137996017933, -0.1229066327214241, 0.07591652125120163, -0.008371543139219284, -0.11374551802873611, 0.041749563068151474, 0.061815518885850906, 0.006898236460983753, -0.08100619167089462, 0.03494752198457718, -0.02532889135181904, 0.007250601425766945, 0.07660176604986191, 0.08424440771341324, 0.04020397737622261, 0.015080454759299755, 0.05930217355489731, -0.0029006132390350103, 0.045117367058992386, 0.08969759196043015, -0.012103110551834106, -0.03523692861199379, 0.005686088930815458, 0.029418574646115303, -0.03433149307966232, -0.027455421164631844, -0.03147218003869057, 0.04295722022652626, -0.06847383081912994, -0.09958434104919434, 0.02353629469871521, 0.0953463464975357, -0.011901567690074444, 0.01738819107413292, 0.020273594185709953, 0.023452192544937134, 0.04318612441420555, 0.014595851302146912, -0.014012649655342102, 0.0397748127579689, 0.041052307933568954, -0.09829384088516235, 0.06302124261856079, -0.0030880665872246027, -0.04195322468876839, 0.06581512093544006, -0.00035628204932436347, -0.022621208801865578, -0.03599851205945015, 0.09838622063398361, -0.009202554821968079, 0.004599402658641338, 0.02576877735555172, 0.03524944931268692, -0.021835073828697205, -0.03400256112217903, 0.07179033756256104, 0.05450018122792244, 0.012864098884165287, 0.005240574944764376, 0.04359962418675423, 0.04381409287452698, 0.010084406472742558, -0.027390262112021446, -0.017584197223186493, 0.02187756448984146, -0.05579259246587753]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the embeddings of the images"
      ],
      "metadata": {
        "id": "6d6p_eIvfu9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "A1=create_image_embedding(\"/content/images/Ahmad-1.jpg\")\n",
        "A2=create_image_embedding(\"/content/images/Ahmad-2.jpg\")\n",
        "A3=create_image_embedding(\"/content/images/Ahmad-3.jpg\")\n",
        "M1=create_image_embedding(\"/content/images/Muneer-1.png\")\n",
        "M2=create_image_embedding(\"/content/images/Muneer-2.png\")\n",
        "M3=create_image_embedding(\"/content/images/Muneer-3.png\")"
      ],
      "metadata": {
        "id": "vTpoTRSbTEFI"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# installing Milvus database"
      ],
      "metadata": {
        "id": "tRQ4TuIzfqHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU milvus-lite\n",
        "!pip install pymilvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "frjlhSBvXFBE",
        "outputId": "fe161d1f-713b-493a-eed3-ac913e6e403a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymilvus\n",
            "  Downloading pymilvus-2.5.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (75.1.0)\n",
            "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.29.3)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.0.1)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Downloading pymilvus-2.5.3-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, grpcio, pymilvus\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.69.0\n",
            "    Uninstalling grpcio-1.69.0:\n",
            "      Successfully uninstalled grpcio-1.69.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.67.1 pymilvus-2.5.3 ujson-5.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc"
                ]
              },
              "id": "51b78303a0dd45cca7b252c95952a335"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating Milvus database"
      ],
      "metadata": {
        "id": "STS1JIEyflRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")"
      ],
      "metadata": {
        "id": "A5A7F2tkXbCS"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating the Milvus vector database"
      ],
      "metadata": {
        "id": "CEbYcuxOfcYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension = 512 # the vector we will use in this demo has 384 dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "JkiwuZTaYBlQ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making a database of our data means metadata"
      ],
      "metadata": {
        "id": "YaqP_FywfQNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Ahmad\",\"vector\": A1 },\n",
        "    {\"id\": 2, \"person_name\": \"Ahmad\",\"vector\": A2 },\n",
        "    {\"id\": 3, \"person_name\": \"Ahmad\",\"vector\": A3 },\n",
        "    {\"id\": 4, \"person_name\": \"Muneer\",\"vector\": M1 },\n",
        "    {\"id\": 5, \"person_name\": \"Muneer\",\"vector\": M2 },\n",
        "    {\"id\": 6, \"person_name\": \"Muneer\",\"vector\": M3 }\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "Eao9-8DAZVSE"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inserting embeddings int the Milvus vector store"
      ],
      "metadata": {
        "id": "7hAAXydzfFSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZmO_2Z8KfFNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data,\n",
        "    partition_name=\"images\"\n",
        ")"
      ],
      "metadata": {
        "id": "dA4Db_EUZmJL"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing image from embeddings"
      ],
      "metadata": {
        "id": "fWIwZfURe6JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ress = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data = [A1],\n",
        "    limit = 1,\n",
        "    output_fields=[\"person_name\"],\n",
        ")\n",
        "print(ress)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBzSTh4jazb2",
        "outputId": "c82baf36-5e18-4f56-97e1-0e5ce6faa883"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 1.0, 'entity': {'person_name': 'Ahmad'}}]\"] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# creating embeddings of the new image"
      ],
      "metadata": {
        "id": "L3a-3ZJue03t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A4=create_image_embedding(\"/content/images/Ahmad.jpg\")"
      ],
      "metadata": {
        "id": "McSFtrsSa-m5"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YOK7fRSJdTOL",
        "outputId": "e285f81f-681a-4369-922f-c711274a18e6"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.0011163094313815236,\n",
              " -0.043538253754377365,\n",
              " -0.021694833412766457,\n",
              " -0.0011043580016121268,\n",
              " -0.03609771654009819,\n",
              " -0.0410459041595459,\n",
              " 0.01998523436486721,\n",
              " -0.01748082786798477,\n",
              " 0.06280048936605453,\n",
              " -0.00991627387702465,\n",
              " 0.010830176062881947,\n",
              " -0.01234399899840355,\n",
              " -0.018301719799637794,\n",
              " -0.005017634015530348,\n",
              " 0.03096856363117695,\n",
              " 0.009759867563843727,\n",
              " 0.015337083488702774,\n",
              " -0.02245783805847168,\n",
              " -0.016232816502451897,\n",
              " 0.03889907896518707,\n",
              " 0.05024350807070732,\n",
              " 0.06869260966777802,\n",
              " 0.05720378831028938,\n",
              " -0.040649641305208206,\n",
              " -0.08763627707958221,\n",
              " 0.015370333567261696,\n",
              " 0.014402925968170166,\n",
              " 0.03495435044169426,\n",
              " -0.056525371968746185,\n",
              " -0.028037382289767265,\n",
              " -0.02394195646047592,\n",
              " 0.07918853312730789,\n",
              " -0.004698561504483223,\n",
              " 0.017562812194228172,\n",
              " 0.02613065391778946,\n",
              " 0.025571387261152267,\n",
              " 0.019872164353728294,\n",
              " 0.051330361515283585,\n",
              " -0.016790147870779037,\n",
              " -0.07884030789136887,\n",
              " 0.052945155650377274,\n",
              " -0.015103340148925781,\n",
              " 0.057181216776371,\n",
              " -0.0228253360837698,\n",
              " -0.05506426468491554,\n",
              " -0.02991681918501854,\n",
              " 0.02858314849436283,\n",
              " -0.025760961696505547,\n",
              " -0.06728758662939072,\n",
              " -0.012099097482860088,\n",
              " 0.03275805711746216,\n",
              " 0.07249666005373001,\n",
              " -0.012358823791146278,\n",
              " -0.0658082515001297,\n",
              " -0.048195287585258484,\n",
              " -0.004722816403955221,\n",
              " -0.0037005143240094185,\n",
              " 0.05710822343826294,\n",
              " 0.08449365943670273,\n",
              " 0.0917726531624794,\n",
              " -0.05312551185488701,\n",
              " 0.017582444474101067,\n",
              " -0.01660727895796299,\n",
              " -0.03331756219267845,\n",
              " -0.0018103303154930472,\n",
              " 0.05882996693253517,\n",
              " 0.006128467619419098,\n",
              " -0.015045448206365108,\n",
              " 0.017297139391303062,\n",
              " 1.5485133189940825e-05,\n",
              " -0.0487261563539505,\n",
              " -0.02361449971795082,\n",
              " 0.11121010035276413,\n",
              " -0.02996545098721981,\n",
              " 0.03575141355395317,\n",
              " -0.03615801781415939,\n",
              " -0.0315261147916317,\n",
              " -0.0405428372323513,\n",
              " -0.09191223233938217,\n",
              " 0.010225369594991207,\n",
              " -0.030889518558979034,\n",
              " -0.03757106885313988,\n",
              " 0.0047035301104187965,\n",
              " -0.010965637862682343,\n",
              " -0.013368986546993256,\n",
              " -0.04695221781730652,\n",
              " 0.0045218984596431255,\n",
              " -0.0014630005462095141,\n",
              " -0.10693477094173431,\n",
              " 0.030621813610196114,\n",
              " -0.050141315907239914,\n",
              " 0.04703792557120323,\n",
              " 0.05782358720898628,\n",
              " -0.00011321812053211033,\n",
              " -0.03865628316998482,\n",
              " -0.027676329016685486,\n",
              " 0.02622404135763645,\n",
              " 0.007563682273030281,\n",
              " -0.024308785796165466,\n",
              " -0.0736050084233284,\n",
              " 0.00915574748069048,\n",
              " 0.027864782139658928,\n",
              " -0.01299953181296587,\n",
              " 0.054980866611003876,\n",
              " 0.03544723615050316,\n",
              " -0.026665695011615753,\n",
              " 0.07603047043085098,\n",
              " -0.020042911171913147,\n",
              " -0.011339929886162281,\n",
              " 0.05564418062567711,\n",
              " -0.04796525463461876,\n",
              " -0.02892109379172325,\n",
              " -0.028378376737236977,\n",
              " -0.03948117420077324,\n",
              " -0.03666042909026146,\n",
              " -0.10311557352542877,\n",
              " 0.0010363762266933918,\n",
              " -0.005851557943969965,\n",
              " 0.00980996061116457,\n",
              " 0.00483561959117651,\n",
              " -0.033779606223106384,\n",
              " -0.0005992420483380556,\n",
              " -0.05123905465006828,\n",
              " 0.00962256919592619,\n",
              " -0.054296936839818954,\n",
              " -0.025144333019852638,\n",
              " 0.03986520692706108,\n",
              " 0.04517139494419098,\n",
              " 0.009060246869921684,\n",
              " -0.029337672516703606,\n",
              " -0.05050011724233627,\n",
              " 0.022846175357699394,\n",
              " 0.037417374551296234,\n",
              " -0.02500215172767639,\n",
              " -0.04401451721787453,\n",
              " 0.06429360806941986,\n",
              " -0.03404077887535095,\n",
              " 0.010176524519920349,\n",
              " 0.002582356333732605,\n",
              " 0.04653169587254524,\n",
              " 0.059450991451740265,\n",
              " -0.005590197164565325,\n",
              " 0.03924987092614174,\n",
              " 0.06873457878828049,\n",
              " -0.015838921070098877,\n",
              " -0.04928422346711159,\n",
              " -0.07980912178754807,\n",
              " -0.050826553255319595,\n",
              " 0.04019526019692421,\n",
              " 0.09637497365474701,\n",
              " 0.04196787253022194,\n",
              " -0.0014947567833587527,\n",
              " 0.005110112950205803,\n",
              " -0.017282016575336456,\n",
              " -0.016980508342385292,\n",
              " -0.04514552652835846,\n",
              " -0.026324033737182617,\n",
              " 0.0020064704585820436,\n",
              " -0.05689014494419098,\n",
              " -0.016231846064329147,\n",
              " 0.0731702595949173,\n",
              " -0.0185294970870018,\n",
              " -0.0020353912841528654,\n",
              " 0.0389886237680912,\n",
              " 0.04329344630241394,\n",
              " -0.039808448404073715,\n",
              " -0.01266467571258545,\n",
              " -0.09582771360874176,\n",
              " 0.039230022579431534,\n",
              " -0.026440121233463287,\n",
              " 0.04268037527799606,\n",
              " 0.0524432398378849,\n",
              " -0.040950190275907516,\n",
              " -0.04365793615579605,\n",
              " -0.021368080750107765,\n",
              " -0.04406287148594856,\n",
              " 0.007911873050034046,\n",
              " 0.00016921162023209035,\n",
              " 0.03720288351178169,\n",
              " -0.0036025044973939657,\n",
              " -0.05617471784353256,\n",
              " 0.06794356554746628,\n",
              " -0.02675546519458294,\n",
              " -0.047422103583812714,\n",
              " -0.08066507428884506,\n",
              " 0.055718012154102325,\n",
              " -0.0036143457982689142,\n",
              " 0.03699234500527382,\n",
              " -0.026629392057657242,\n",
              " 0.03605841100215912,\n",
              " 0.10879521816968918,\n",
              " -0.03378909081220627,\n",
              " -0.026336153969168663,\n",
              " 0.02462555654346943,\n",
              " 0.05138668045401573,\n",
              " 0.038357485085725784,\n",
              " 0.0013813045807182789,\n",
              " 0.0827016681432724,\n",
              " -0.06123057007789612,\n",
              " 0.005730027798563242,\n",
              " 0.032787397503852844,\n",
              " 0.07997651398181915,\n",
              " -0.0355948880314827,\n",
              " -0.018528319895267487,\n",
              " -0.0013524624519050121,\n",
              " 0.05368483066558838,\n",
              " 0.008506590500473976,\n",
              " -0.04437443986535072,\n",
              " -0.03993338346481323,\n",
              " 0.03381503000855446,\n",
              " 0.09377148002386093,\n",
              " 0.03555216267704964,\n",
              " 0.002440175274387002,\n",
              " 0.016834350302815437,\n",
              " -0.043587952852249146,\n",
              " -0.0016032749554142356,\n",
              " 0.00547167519107461,\n",
              " -0.0545746386051178,\n",
              " -0.02269340306520462,\n",
              " 0.06591283529996872,\n",
              " 0.04346085712313652,\n",
              " -0.03087546117603779,\n",
              " -0.040858618915081024,\n",
              " -0.05165933817625046,\n",
              " 0.028973009437322617,\n",
              " 0.019737469032406807,\n",
              " 0.0042529902420938015,\n",
              " 0.009706204757094383,\n",
              " 0.004864699672907591,\n",
              " 0.08465629816055298,\n",
              " 0.053155045956373215,\n",
              " -0.05503883212804794,\n",
              " -0.04858319088816643,\n",
              " -0.020443370565772057,\n",
              " -0.028912901878356934,\n",
              " 0.009615921415388584,\n",
              " -0.004365244880318642,\n",
              " -0.00946440827101469,\n",
              " -0.04695631191134453,\n",
              " -0.06563043594360352,\n",
              " 0.07694759219884872,\n",
              " -0.02940220572054386,\n",
              " 0.06244966760277748,\n",
              " -0.03442061319947243,\n",
              " -0.017158813774585724,\n",
              " 0.09437119215726852,\n",
              " -0.016527647152543068,\n",
              " 0.12561744451522827,\n",
              " 0.02290327101945877,\n",
              " -0.01299967896193266,\n",
              " -0.0702977254986763,\n",
              " -0.02248443104326725,\n",
              " -0.03329768776893616,\n",
              " -0.05624198168516159,\n",
              " 0.008172564208507538,\n",
              " 0.005569924134761095,\n",
              " -0.019644102081656456,\n",
              " -0.0664852112531662,\n",
              " 0.05124323070049286,\n",
              " -0.03439583256840706,\n",
              " 0.009527651593089104,\n",
              " -0.027864936739206314,\n",
              " -0.002578765619546175,\n",
              " 0.03287079930305481,\n",
              " 0.03300456702709198,\n",
              " -0.00561617873609066,\n",
              " -0.06913113594055176,\n",
              " 0.025775333866477013,\n",
              " 0.050573743879795074,\n",
              " -0.0003878441930282861,\n",
              " 0.04128275811672211,\n",
              " 0.016533639281988144,\n",
              " 0.020709063857793808,\n",
              " 0.06616594642400742,\n",
              " 0.06295060366392136,\n",
              " -0.0067281280644237995,\n",
              " -0.07303202897310257,\n",
              " -0.008287898264825344,\n",
              " -0.06624635308980942,\n",
              " 0.03498214855790138,\n",
              " -0.005670906510204077,\n",
              " 0.003849571570754051,\n",
              " 0.01739273965358734,\n",
              " -0.1391839236021042,\n",
              " -0.0779334083199501,\n",
              " -0.06378048658370972,\n",
              " -0.05623558163642883,\n",
              " 0.007476715371012688,\n",
              " -0.00863333698362112,\n",
              " 0.04340579733252525,\n",
              " 0.030337654054164886,\n",
              " 0.027522504329681396,\n",
              " -0.001323277479968965,\n",
              " -0.05241958051919937,\n",
              " -0.042912665754556656,\n",
              " -0.0549280010163784,\n",
              " 0.02690315432846546,\n",
              " -0.051058173179626465,\n",
              " -0.007871515117585659,\n",
              " -0.027630507946014404,\n",
              " 0.0010644543217495084,\n",
              " 0.0032154517248272896,\n",
              " 0.006059718783944845,\n",
              " -0.03258487582206726,\n",
              " 0.00518046785145998,\n",
              " -0.006146128289401531,\n",
              " 0.0009206532267853618,\n",
              " -0.023434363305568695,\n",
              " 0.08024768531322479,\n",
              " -0.04343332350254059,\n",
              " 0.055295124650001526,\n",
              " 0.04359525442123413,\n",
              " -0.07928269356489182,\n",
              " -0.11282214522361755,\n",
              " -0.005726329050958157,\n",
              " 0.009312417358160019,\n",
              " 0.006580137647688389,\n",
              " 0.057257961481809616,\n",
              " 0.083218514919281,\n",
              " -0.08893430978059769,\n",
              " -0.033599697053432465,\n",
              " -0.08556738495826721,\n",
              " 0.009635036811232567,\n",
              " 0.03518529608845711,\n",
              " 0.02830168977379799,\n",
              " -0.0009109876700676978,\n",
              " -0.02318473905324936,\n",
              " 0.014881262555718422,\n",
              " 0.0427919402718544,\n",
              " 0.01825932040810585,\n",
              " -0.009320732206106186,\n",
              " -0.004618624225258827,\n",
              " 0.009760593064129353,\n",
              " -0.0074083576910197735,\n",
              " 0.0012797664385288954,\n",
              " 0.02133016288280487,\n",
              " 0.01939440332353115,\n",
              " -0.09021949768066406,\n",
              " 0.00481994915753603,\n",
              " -0.07617095857858658,\n",
              " 0.04564787074923515,\n",
              " -0.012868202291429043,\n",
              " -0.05750829353928566,\n",
              " -0.04642108455300331,\n",
              " -0.001764932880178094,\n",
              " -0.02727554738521576,\n",
              " 0.004776874557137489,\n",
              " 0.052060533314943314,\n",
              " -0.061260517686605453,\n",
              " 0.032302651554346085,\n",
              " 0.0111354636028409,\n",
              " -0.033169060945510864,\n",
              " 0.03485284745693207,\n",
              " 0.027116432785987854,\n",
              " 0.0016568440478295088,\n",
              " 0.003928860183805227,\n",
              " -0.03727317973971367,\n",
              " 0.06493858993053436,\n",
              " -0.04280515015125275,\n",
              " 0.0741325169801712,\n",
              " -0.006858884356915951,\n",
              " 0.08258368074893951,\n",
              " -0.03892149776220322,\n",
              " -0.0968969389796257,\n",
              " -0.03601638972759247,\n",
              " 0.0009659562492743134,\n",
              " -0.03435418754816055,\n",
              " -0.030015913769602776,\n",
              " -0.01914549060165882,\n",
              " -0.10054702311754227,\n",
              " -0.05419164523482323,\n",
              " 0.02790466882288456,\n",
              " -0.07203920930624008,\n",
              " 0.0780186802148819,\n",
              " 0.0017204638570547104,\n",
              " 0.02113555744290352,\n",
              " 0.006990603171288967,\n",
              " 0.05864810198545456,\n",
              " -0.06351009011268616,\n",
              " 0.06097014620900154,\n",
              " -0.06958366930484772,\n",
              " 0.05323661491274834,\n",
              " 0.023051602765917778,\n",
              " -0.014880428090691566,\n",
              " 0.06705299764871597,\n",
              " 0.01746855489909649,\n",
              " 0.06623783707618713,\n",
              " 0.0175704974681139,\n",
              " 0.00993081834167242,\n",
              " -0.04270884394645691,\n",
              " 0.02696712128818035,\n",
              " 0.0010938758496195078,\n",
              " -0.01599062979221344,\n",
              " -0.020196815952658653,\n",
              " 0.053687684237957,\n",
              " -0.03987741842865944,\n",
              " 0.007182018365710974,\n",
              " 0.034978996962308884,\n",
              " -0.012883523479104042,\n",
              " -0.024473536759614944,\n",
              " 0.04292922094464302,\n",
              " -0.040697693824768066,\n",
              " 0.0015022868756204844,\n",
              " 0.006062049884349108,\n",
              " -0.04430541768670082,\n",
              " -0.017717717215418816,\n",
              " 0.009938360191881657,\n",
              " -0.07029663026332855,\n",
              " -0.02141287364065647,\n",
              " 0.02545984461903572,\n",
              " 0.005693543702363968,\n",
              " -0.01927543245255947,\n",
              " 0.0741831362247467,\n",
              " 0.09237326681613922,\n",
              " -0.05558282509446144,\n",
              " 0.0042551797814667225,\n",
              " -0.01566835306584835,\n",
              " -0.012576104141771793,\n",
              " -0.07662870734930038,\n",
              " -0.03424689918756485,\n",
              " 0.06237225979566574,\n",
              " 0.0012591661652550101,\n",
              " 0.013932500965893269,\n",
              " 0.0017990785418078303,\n",
              " 0.0023963265120983124,\n",
              " -0.04624912515282631,\n",
              " -0.019373107701539993,\n",
              " 0.013226203620433807,\n",
              " 0.003068417077884078,\n",
              " -0.029470596462488174,\n",
              " -0.09454765170812607,\n",
              " -0.06600163131952286,\n",
              " 0.034155286848545074,\n",
              " -0.06406175345182419,\n",
              " 0.00014013184409122914,\n",
              " 0.022841712459921837,\n",
              " 0.03378066048026085,\n",
              " 0.07383210957050323,\n",
              " 0.017620578408241272,\n",
              " -0.06916113942861557,\n",
              " -0.058165233582258224,\n",
              " 0.06719311326742172,\n",
              " 0.10532381385564804,\n",
              " 0.004841464105993509,\n",
              " 0.04977047070860863,\n",
              " -0.03842056170105934,\n",
              " 0.026987122371792793,\n",
              " 0.00122077448759228,\n",
              " -0.02941298671066761,\n",
              " 0.06365187466144562,\n",
              " -0.018533559516072273,\n",
              " 0.02128692902624607,\n",
              " 0.030741458758711815,\n",
              " 0.01844928227365017,\n",
              " -0.06890139728784561,\n",
              " -0.0324687659740448,\n",
              " 1.7824997485149652e-05,\n",
              " 0.028640830889344215,\n",
              " 0.07842790335416794,\n",
              " 0.051940470933914185,\n",
              " 0.01632474921643734,\n",
              " 0.0098396185785532,\n",
              " 0.02373291365802288,\n",
              " -0.08378440141677856,\n",
              " 0.0013802183093503118,\n",
              " 0.00591467646881938,\n",
              " -0.05698131397366524,\n",
              " -0.0367572158575058,\n",
              " 0.04090388864278793,\n",
              " -0.010865542106330395,\n",
              " 0.04151062294840813,\n",
              " 0.03247273340821266,\n",
              " 0.05093587189912796,\n",
              " -0.035027239471673965,\n",
              " -0.003985156770795584,\n",
              " 0.05191643536090851,\n",
              " 0.036318764090538025,\n",
              " 0.06096161901950836,\n",
              " 0.033372554928064346,\n",
              " -0.023653840646147728,\n",
              " -0.023119186982512474,\n",
              " -0.009880618192255497,\n",
              " 0.017940476536750793,\n",
              " -0.004359088838100433,\n",
              " 0.032586678862571716,\n",
              " -0.0211173202842474,\n",
              " -0.027293527498841286,\n",
              " 0.01715599000453949,\n",
              " -0.05987865477800369,\n",
              " -0.07436320185661316,\n",
              " 0.024218011647462845,\n",
              " -0.04751451686024666,\n",
              " 0.011894374154508114,\n",
              " 0.02133186347782612,\n",
              " 0.052811168134212494,\n",
              " 0.07037560641765594,\n",
              " 0.044271938502788544,\n",
              " -0.008069885894656181,\n",
              " 0.05177036300301552,\n",
              " -0.03311239182949066,\n",
              " -0.06203191727399826,\n",
              " 0.030395515263080597,\n",
              " -0.0452677421271801,\n",
              " 0.08611736446619034,\n",
              " -0.013725828379392624,\n",
              " -0.05438793823122978,\n",
              " 0.03962235525250435,\n",
              " -0.07599760591983795,\n",
              " -0.0017208103090524673,\n",
              " 0.13868741691112518,\n",
              " -0.02709406614303589,\n",
              " -0.0318567119538784]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with the new image"
      ],
      "metadata": {
        "id": "UWQzhaxkesih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resul = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data = [A4],\n",
        "    limit = 3,\n",
        "    output_fields=[\"id\",\"person_name\"],\n",
        ")\n",
        "print(resul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffmxHWHydVAP",
        "outputId": "a1fdebb1-9840-4f2d-f38a-0d313c02d6fa"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 5, 'distance': 0.5289016962051392, 'entity': {'person_name': 'Muneer', 'id': 5}}, {'id': 6, 'distance': 0.3440612256526947, 'entity': {'person_name': 'Muneer', 'id': 6}}, {'id': 4, 'distance': 0.15956392884254456, 'entity': {'person_name': 'Muneer', 'id': 4}}]\"] \n"
          ]
        }
      ]
    }
  ]
}